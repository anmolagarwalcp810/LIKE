{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJQ1vkUS-4hv"
   },
   "source": [
    "# 0. Fake News Labeler\n",
    "\n",
    "This notebook contains code to label the FNC-Core dataset with a team of pre-trained experts.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The FNC (Fake-News-Covid) dataset is a twitter-sampled stream of tweets for fake news detection.It is collected along with its social context of usernames, account details, retweets, likes, quote tweets, among other features.\n",
    "\n",
    "FNC has several components:\n",
    "\n",
    "- **FNC-Raw**: The raw stream collected from the Twitter Sampled Stream\n",
    "- **FNC-Filtered**: The filtered stream obtained from the Twitter Sampled Stream with covid-related keyword filters.\n",
    "- **FNC-Neighbors**: Samples from FNC-Raw that were not filtered into FNC-Filtered due to missing, censored, or mispelled keywords, but are semantically similar to FNC-Filtered. We detect these with embedding extensions.\n",
    "- **FNC-Extended**: FNC-Filtered combined with FNC-Neighbors to yield a more complete filtered dataset. We can refer to monthly subsets as FNC-Extended-\\<MonthYear\\>, e.g. FNC-Extended-Jan2020\n",
    "\n",
    "These are the unlabeled parts of FNC. With this notebook, we can label a subset of FNC-Extended with high accuracy. These also fall under several components:\n",
    "\n",
    "- **FNC-Extended-Oracle**: Samples from FNC-Extended that are labeled with human annotators. FNC-Extended-Oracle has 10k samples. Since FNC-Extended spans 25 months, we have 400 labeled samples per month.\n",
    "- **FNC-Expert-\\<Expert\\>-\\<MonthYear\\>**: The FNC-Extended-\\<MonthYear\\> subset is labeled by an expert with name \\<Expert\\>.\n",
    "- **FNC-Labeled**: We integrate labels from several experts to generate the final labeled set. We can evaluate labeling accuracy on the intersection with FNC-Extended-Oracle. Monthly subsets are FNC-Labeled-\\<MonthYear\\>\n",
    "\n",
    "## This Notebook\n",
    "In this notebook, we will:\n",
    "\n",
    "- Generate FNC-Filtered (unless the raw data is already of this format...should recheck)\n",
    "- Possibly generate FNC-Neighbors (unless raw data is already of this format...should recheck)\n",
    "- Generate FNC-Expert. For this, we have a list of experts already generated. We will use EdnaML Deployments to load an expert, then load our data from Azure, then label each point, and save the generated label. If a model abstains for some point, we will score that as a [-1]. True News is [1]. Fake News is [0]. Then, the labels will be saved to this instance. We will download the labels, labeled as FNC-Expert-[ExpertName]-[MonthYear]. For each file, we will also save any necessary label characteristics in the same line, i.e.: [label,L-score, model-l-score-threshold, etc]\n",
    "- Possibly Generate FNC-Labeled. Once we have several expert labeled sets, we will integrate them together using Snorkel, EEWS, etc... Snorkel is easy to implement. We might skip EEWS and ATEAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OMDUT5TWE7-N",
    "outputId": "1efdaa60-cf20-4c82-a065-daf762ec5e38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
      "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.2 tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUETMOy3gGvu"
   },
   "source": [
    "# 1. Setup -- Gdrive Connect, Git clone, Model  Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4h8JjeAfpDo"
   },
   "source": [
    "## Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w_P6hPRDqyi4",
    "outputId": "d9ee5d1f-14fa-4e28-bbdd-a22603660a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug 20 01:47:33 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   53C    P8    13W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZtdWNypnP72"
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os, glob, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiPHbFAZjWlv",
    "outputId": "8ff82d61-fe39-4d38-ba30-295a13e109ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Set Gogle Drive Connection\n",
    "#if not osp.exists(\"./drive\"):\n",
    "from google.colab import drive\n",
    "\n",
    "#https://stackoverflow.com/questions/69822304/google-colab-google-drive-can%c2%b4t-be-mounted-anymore-browser-popup-google-dri\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqJoyEW1f_a1"
   },
   "source": [
    "## Git Clone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oisq4kE8IMHi"
   },
   "source": [
    "### From Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJfycQTLVkEj"
   },
   "outputs": [],
   "source": [
    "! rm -rf -- EdnaML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHV0k2japSDs"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goBMKUmagBIx",
    "outputId": "90f0e266-813f-447b-bc00-476a8ad6a336"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'EdnaML'...\n",
      "remote: Enumerating objects: 9559, done.\u001b[K\n",
      "remote: Counting objects: 100% (1462/1462), done.\u001b[K\n",
      "remote: Compressing objects: 100% (481/481), done.\u001b[K\n",
      "remote: Total 9559 (delta 901), reused 1385 (delta 833), pack-reused 8097\u001b[K\n",
      "Receiving objects: 100% (9559/9559), 3.32 MiB | 5.42 MiB/s, done.\n",
      "Resolving deltas: 100% (6295/6295), done.\n",
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "! git clone -b master https://github.com/asuprem/EdnaML\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I9ZS94WkOIeV",
    "outputId": "721cf35c-8bee-4aaa-d236-ca8ced6f0abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting setuptools==61.2.0\n",
      "  Downloading setuptools-61.2.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.7.2\n",
      "    Uninstalling setuptools-67.7.2:\n",
      "      Successfully uninstalled setuptools-67.7.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
      "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 61.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed setuptools-61.2.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "_distutils_hack",
         "pkg_resources",
         "setuptools"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/EdnaML\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (1.2.2)\n",
      "Requirement already satisfied: torch>=1.10.* in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (2.0.1+cu118)\n",
      "Collecting torchinfo>=1.6.5 (from ednaml==0.1.5)\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: torchvision>=0.11.* in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (0.15.2+cu118)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (9.4.0)\n",
      "Requirement already satisfied: tqdm>=4.63.* in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (4.66.1)\n",
      "Collecting sentencepiece>=0.1.96 (from ednaml==0.1.5)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (2.4.0)\n",
      "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from ednaml==0.1.5) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->ednaml==0.1.5) (3.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.*->ednaml==0.1.5) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.*->ednaml==0.1.5) (3.27.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.*->ednaml==0.1.5) (16.0.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.11.*->ednaml==0.1.5) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.*->ednaml==0.1.5) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.11.*->ednaml==0.1.5) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.*->ednaml==0.1.5) (1.3.0)\n",
      "Installing collected packages: sentencepiece, torchinfo, ednaml\n",
      "  Running setup.py develop for ednaml\n",
      "Successfully installed ednaml-0.1.5 sentencepiece-0.1.99 torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install setuptools==61.2.0\n",
    "!pip install -e EdnaML/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5j3WfN0fpIT"
   },
   "source": [
    "###  From PyPi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7dkOhZi08dU"
   },
   "outputs": [],
   "source": [
    "#! python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwqgjiZ331ik"
   },
   "outputs": [],
   "source": [
    "#! pip3 install --pre ednaml==0.1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQCbxSJDf7Ix"
   },
   "source": [
    "## AlBERT / ModelFile Data Download\n",
    "\n",
    "(And assume they are FNC-Extended-MonthYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27LK1AmgfuCk"
   },
   "outputs": [],
   "source": [
    "# Commented in for Sp 23\n",
    "!cp ./drive/MyDrive/Datasets/PreTrained/Albertv2/30k* .\n",
    "!cp ./drive/MyDrive/Datasets/PreTrained/Albertv2/pytorch_model.bin ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfspmIFRmgd6"
   },
   "source": [
    "# Restart Runtime Here!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KjvT_ZJovGY"
   },
   "source": [
    "# 2. Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoQKEy4Douez"
   },
   "outputs": [],
   "source": [
    "tweet_file = \"tweets-2020-01-22\"\n",
    "proxy = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqCdOF7tCj8N"
   },
   "source": [
    "# 3. Generating FNC-Filtered from FNC-Raw\n",
    "\n",
    "Here, we will use an EdnaML workflow to generate FNC-Filtered from FNC-Raw. This is not really a learnable model, rather a simple keyword matcher.\n",
    "\n",
    "Essentially, we will build a workflow where we:\\\n",
    "\n",
    "1. Crawl an FNC Source and download if it does not exist\n",
    "2. Create datashards from the Source, with only testing data since there is no \"training\" to be performed\n",
    "3. Deploy a ModelAbstract model that reads a batch of raw text data, and checks whether elements of this batch contain our keywords. If they do, we label 1. If they do not, we label 0.\n",
    "4. The Deployment thus generates 2 outputs: a file containing fnc-filtered, and a file fnc-nonfiltered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEwLZP2RnPe3"
   },
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!rm -rf -- test-datashard-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbgIkVzUi8RM"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "upU2x5V1CFqi",
    "outputId": "1716f17a-ee0c-44cb-d0a8-e7749ebad0c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fj4K8740CFoI"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/filtered/config.yml\"\n",
    "crawler_generator = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filter_model_deployment = \"./EdnaML/profiles/FNC/fnc-filtered.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lstv_fo4CFlo"
   },
   "outputs": [],
   "source": [
    "ed = EdnaDeploy(config=config)\n",
    "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"azfile\"] = \"%s.json.gz\"%tweet_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BZNRsfX7HAGj",
    "outputId": "3a63b4dc-9fc8-48cc-a289-0f9846f0582b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:38:07 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "23:38:07 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "23:38:07 Adding a model, from /content/EdnaML/profiles/FNC/fnc-filtered.py, with inferred name FNCFilter\n",
      "23:38:07 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-filtered.py, with inferred name FNCFilterDeployment\n",
      "23:38:07 ****************************************\n",
      "23:38:07 \n",
      "23:38:07 \n",
      "23:38:07 Using the following configuration:\n",
      "23:38:07 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      shard_replace: false\n",
      "      shardname: fnc-raw-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS: {}\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS:\n",
      "    basename: tweets-2020-01-22\n",
      "    filtered_output: filtered\n",
      "    unfiltered_output: unfiltered\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS: {}\n",
      "    DATAREADER: DataReader\n",
      "    DATASET_ARGS: {}\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS: {}\n",
      "  EPOCHS: 10\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 1\n",
      "LOGGING:\n",
      "  INPUT_SIZE: null\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS: []\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCFilter\n",
      "  MODEL_BASE: NoBase\n",
      "  MODEL_KWARGS:\n",
      "    filter_list:\n",
      "    - covid\n",
      "    - corona\n",
      "    - mask\n",
      "    - wuhan\n",
      "    - n95\n",
      "    - sars\n",
      "    - monkey\n",
      "    - pandemic\n",
      "    - social\n",
      "    - quarantin\n",
      "    - virus\n",
      "    - infect\n",
      "    - lock\n",
      "    - ppe\n",
      "    - variant\n",
      "    - vaccine\n",
      "    - travel\n",
      "    - omicron\n",
      "    - ivermectin\n",
      "    - plandemic\n",
      "    - 5g\n",
      "    - gates\n",
      "    - hoax\n",
      "    - bioweapon\n",
      "    - bat\n",
      "    - fauci\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN: {}\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: false\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: offshelf\n",
      "  MODEL_CORE_NAME: fnc-filter\n",
      "  MODEL_QUALIFIER: raw\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 5\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 128\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 128\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "23:38:07 \n",
      "23:38:07 \n",
      "23:38:07 ****************************************\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
      "  warnings.warn(\n",
      "23:38:07 No previous stop detected. Will start from epoch 0\n",
      "23:38:07 Reading data with DataReader AlbertReader\n",
      "23:38:07 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "23:38:07 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "23:38:07 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "23:38:07 Updating GENERATOR to queued class FNCRawGenerator\n",
      "23:38:07 Updating CRAWLER to FNCCrawler\n",
      "23:38:07 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-filtered.py.FNCFilter'>, from file: /content/EdnaML/profiles/FNC/fnc-filtered.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-filtered.py.FNCFilterDeployment'>, from file: /content/EdnaML/profiles/FNC/fnc-filtered.py\n",
      "5637377/5637377 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]\n",
      "Download of tweets-2020-01-22.json.gz to https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:38:11 Generating dataloader `FNCRawGenerator` with `test` mode\n",
      "23:38:16 Generated test data/query generator\n",
      "23:38:16 Loaded ednaml_model_builder from ednaml.models to build model\n",
      "23:38:16 Finished instantiating model with FNCFilter architecture\n",
      "23:38:16 Adding plugins after constructing model\n",
      "23:38:16 No saved model weights provided. Inferring weights path.\n",
      "23:38:16 No previous stop exists. Not loading weights.\n",
      "23:38:16 Model Summary retured the following error:\n",
      "23:38:16 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "23:38:16 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.add(crawler_generator)\n",
    "ed.add(filter_model_deployment)\n",
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkWzzI6XCFjM",
    "outputId": "7da92ca7-2fd2-47af-e3b4-8a215aae1cf9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:38:16 Starting deployment\n",
      "23:38:16 Logging to:\tfnc-filter-v1-offshelf-raw-logger.log\n",
      "23:38:16 Setting up plugin hooks. Plugins will fire during:  always\n",
      "23:38:16 Executing deployment for  1 epochs\n",
      "23:38:16 Starting epoch 0\n",
      "23:38:17 Executing end of epoch steps\n",
      "23:38:17 Completed deployment task.\n"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FOwc42Dv5i6H"
   },
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1grPg6X_5giI",
    "outputId": "071fd1de-4a84-4114-8d6d-b334f9b78cb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'train-datashard-artifacts/fnc-raw*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.exists(tweet_file+\".json\"):\n",
    "  os.remove(tweet_file+\".json\")\n",
    "if os.path.exists(tweet_file+\".json.gz\"):\n",
    "  os.remove(tweet_file+\".json.gz\")\n",
    "! rm test-datashard-artifacts/fnc-raw*\n",
    "! rm train-datashard-artifacts/fnc-raw*\n",
    "! rm test-datashard-artifacts/len.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dckc897vD9t_",
    "outputId": "b62a4daa-b448-4591-d388-7f8601f92c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17718 tweets-2020-01-22-filtered.json\n"
     ]
    }
   ],
   "source": [
    "! wc -l $tweet_file-filtered.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idvTSx5L4rSV",
    "outputId": "87b01a15-3bb0-4e22-a5b2-78255a91e001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6333 tweets-2020-01-22-unfiltered.json\n"
     ]
    }
   ],
   "source": [
    "! wc -l $tweet_file-unfiltered.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBLksdNI5Ukb"
   },
   "source": [
    "## Filtered subset scaling (for class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6wqZBNo5YtY"
   },
   "outputs": [],
   "source": [
    "filter_scale = 1    # Notes: NA\n",
    "unfilter_scale = 1  # Notes: NA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqSK-TBM5Z9v"
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmSTGx8U47rY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tf_filtered = tweet_file + \"-filtered.json\"\n",
    "tf_unfiltered = tweet_file + \"-unfiltered.json\"\n",
    "# Set reduction scale\n",
    "import random\n",
    "random.seed(34598344)\n",
    "# Reduce filtered.json\n",
    "filt_obj = open(tf_filtered, \"r\")\n",
    "filtout_obj = open(tf_filtered + \"2\", \"w\")\n",
    "for row in filt_obj:\n",
    "    if random.random() <= filter_scale:\n",
    "      filtout_obj.write(row)\n",
    "filtout_obj.close()\n",
    "filt_obj.close()\n",
    "# Reduce unfiltered.json\n",
    "unfilt_obj = open(tf_unfiltered, \"r\")\n",
    "unfiltout_obj = open(tf_unfiltered + \"2\", \"w\")\n",
    "for row in unfilt_obj:\n",
    "    if random.random() <= unfilter_scale:\n",
    "      unfiltout_obj.write(row)\n",
    "unfiltout_obj.close()\n",
    "unfilt_obj.close()\n",
    "# Delete old files\n",
    "os.remove(tf_filtered)\n",
    "os.remove(tf_unfiltered)\n",
    "# Rename to old file name\n",
    "os.rename(tf_filtered+\"2\", tf_filtered)\n",
    "os.rename(tf_unfiltered+\"2\", tf_unfiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NItLF9wU5EID",
    "outputId": "010821c1-fd73-48b5-e69b-7ee7ed6f9be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17718 tweets-2020-01-22-filtered.json\n"
     ]
    }
   ],
   "source": [
    "! wc -l $tweet_file-filtered.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIgD01x55EIE",
    "outputId": "5e7342eb-0b08-42cc-fdca-00bc071f10c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6333 tweets-2020-01-22-unfiltered.json\n"
     ]
    }
   ],
   "source": [
    "! wc -l $tweet_file-unfiltered.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDG0xKuTCrT5"
   },
   "source": [
    "# 4. Generating FNC-Neighbors from FNC-Filtered and FNC\n",
    "\n",
    "Here, we will take the json files generated from FNC-Filter: `filter.json` and `unfilter.json`.\n",
    "\n",
    "The filter.json content is used to fine-tune a BERT model. This BERT model implements keyword masking, that is, specific keywords are masked\n",
    "\n",
    "Then we use a cluster_estimator plugin to estimate the best number of clusters with KMeans for the training dataset.\n",
    "\n",
    "Then, we insert a high-density estimator plugin with the best number of clusters as proxies\n",
    "\n",
    "Then, we will use a Deployment to iterate through unfilter. For each, we will generate the features, and use the high-density estimator plugin to check if it exists in the high density set of existing clusters. Note that the unfilter data implements the same masking as the training model. Any samples that exist are placed in `extended.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUiGLd_6sbPG"
   },
   "source": [
    "## 4.1 Finetuning MLM with keyword masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOGkQT_yJPKq"
   },
   "outputs": [],
   "source": [
    "# Cleanup ONLY if starting from scratch, not if already doing 4.1\n",
    "# Also cleanup if switching datasets\n",
    "!rm test-datashard-artifacts/fnc-filtermask*\n",
    "!rm train-datashard-artifacts/fnc-filtermask*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbr7XsGK_ega",
    "outputId": "606afb6e-394a-4e43-eed7-f44165123a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "v38XZXs-_egb",
    "outputId": "294168e6-ec23-4b64-f7e0-e297004b4d8d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YKtTKmW__egb"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/extension/config.yml\"\n",
    "crawler = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filtermask_generator = \"./EdnaML/profiles/FNC/fnc-filtermasked.py\"\n",
    "extension_model = \"./EdnaML/profiles/FNC/fnc-extension.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WbCacu9_egb",
    "outputId": "f8c345c4-bdf7-4f4b-9056-c45a5adc3dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
      "Injected key-value pair:  SAVE.MODEL_VERSION, 1\n",
      "Injected key-value pair:  SAVE.STEP_SAVE_FREQUENCY, 50000\n",
      "Injected key-value pair:  EXECUTION.EPOCHS, 1\n",
      "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
     ]
    }
   ],
   "source": [
    "eml = EdnaML(config=config, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.MODEL_VERSION\", 1), (\"SAVE.STEP_SAVE_FREQUENCY\", 50000), (\"EXECUTION.EPOCHS\", 1)])\n",
    "#eml = EdnaML(config=config, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file)])\n",
    "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file\n",
    "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-unfiltered.json\"%tweet_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_l1QmVo6_egb",
    "outputId": "90147ff9-1c18-4106-f09f-3b134c6b08e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:57:46 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "23:57:46 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "23:57:46 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
      "23:57:46 Adding a model, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
      "23:57:46 Adding a trainer, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModelerTrainer\n",
      "23:57:46 ****************************************\n",
      "23:57:46 \n",
      "23:57:46 \n",
      "23:57:46 Using the following configuration:\n",
      "23:57:46 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS: {}\n",
      "    DATAREADER: DataReader\n",
      "    DATASET_ARGS: {}\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS: {}\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS: {}\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "      test_file: tweets-2020-01-22-unfiltered.json\n",
      "      train_file: tweets-2020-01-22-filtered.json\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: true\n",
      "      keyword_mask: true\n",
      "      keywords:\n",
      "      - covid\n",
      "      - corona\n",
      "      - mask\n",
      "      - wuhan\n",
      "      - n95\n",
      "      - sars\n",
      "      - monkey\n",
      "      - pandemic\n",
      "      - social\n",
      "      - quarantin\n",
      "      - virus\n",
      "      - infect\n",
      "      - lock\n",
      "      - ppe\n",
      "      - variant\n",
      "      - vaccine\n",
      "      - travel\n",
      "      - omicron\n",
      "      - ivermectin\n",
      "      - plandemic\n",
      "      - 5g\n",
      "      - gates\n",
      "      - hoax\n",
      "      - bioweapon\n",
      "      - bat\n",
      "      - fauci\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-filtermask-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 1\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - loss_class: CrossEntropyLoss\n",
      "    loss_kwargs:\n",
      "      ignore_index: -1\n",
      "  LABEL: mask_lm\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - TorchLoss\n",
      "  NAME: mask_lm\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCAlbertModeler\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN: {}\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: fnc-extension\n",
      "  MODEL_QUALIFIER: tweets-2020-01-22\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 50000\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 5\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "23:57:46 \n",
      "23:57:46 \n",
      "23:57:46 ****************************************\n",
      "23:57:46 Previous stop detected. Will attempt to resume from epoch 2, step 0\n",
      "23:57:46 Loaded BaseStorage from ednaml.storage to build Storage\n",
      "23:57:46 Reading data with DataReader AlbertReader\n",
      "23:57:46 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "23:57:46 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "23:57:46 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "23:57:46 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
      "23:57:46 Updating CRAWLER to FNCCrawler\n",
      "23:57:46 Building Transforms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-filtermasked.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a trainer: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:57:47 Building Dataset\n",
      "23:57:47 Generating shards\n",
      "100%|██████████| 1/1 [00:24<00:00, 24.89s/it]\n",
      "23:58:12 Building Dataloader\n",
      "23:58:12 Generated training data generator with 17718 training data points\n",
      "23:58:12 Running classification model with classes: {'fnews': {'classes': 2}}\n",
      "23:58:12 Building Transforms\n",
      "23:58:13 Building Dataset\n",
      "23:58:13 Generating shards\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
      "23:58:19 Building Dataloader\n",
      "23:58:19 Generated test data/query generator\n",
      "23:58:19 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:19 Finished instantiating model with FNCAlbertModeler architecture\n",
      "23:58:19 Adding plugins after constructing model\n",
      "23:58:19 No saved model weights provided.\n",
      "23:58:19 Model Summary retured the following error:\n",
      "23:58:19 Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\", line 295, in forward_pass\n",
      "    _ = model(*x, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/content/EdnaML/src/ednaml/models/ModelAbstract.py\", line 140, in forward\n",
      "    feature_logits, features, secondary_outputs = self.forward_impl(\n",
      "  File \"/content/./EdnaML/profiles/FNC/fnc-extension.py\", line 105, in forward_impl\n",
      "    outputs = self.encoder(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/content/EdnaML/src/ednaml/models/Albert.py\", line 705, in forward\n",
      "    embedding_output = self.embeddings(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/content/EdnaML/src/ednaml/models/Albert.py\", line 140, in forward\n",
      "    words_embeddings = self.word_embeddings(input_ids)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1538, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\", line 162, in forward\n",
      "    return F.embedding(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2210, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "RuntimeError: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 892, in getModelSummary\n",
      "    self.model_summary = summary(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\", line 223, in summary\n",
      "    summary_list = forward_pass(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torchinfo/torchinfo.py\", line 304, in forward_pass\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []\n",
      "\n",
      "23:58:19 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
      "23:58:19 Built optimizer\n",
      "23:58:19 Built scheduler\n",
      "23:58:19 Added TorchLoss with lambda = 1.0 and loss arguments {'loss_class': 'CrossEntropyLoss', 'loss_kwargs': {'ignore_index': -1}}\n",
      "23:58:19 Built loss function\n",
      "23:58:19 Built loss optimizer\n",
      "23:58:19 Built loss scheduler\n",
      "23:58:19 Loaded BaseStorage from ednaml.storage to build Storage\n",
      "23:58:19 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n",
      "INPUT SIZE ====  [16, 512]\n",
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "eml.add(crawler)\n",
    "eml.add(filtermask_generator)\n",
    "eml.add(extension_model)\n",
    "eml.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf5tx5mF_egb",
    "outputId": "cad2362d-6ca1-4ed3-d578-299d56cab3b8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:58:25 Starting training\n",
      "23:58:25 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
      "23:58:25 Models will be saved to local directory:\tfnc-extension-v1-albert-tweets-2020-01-22\n",
      "23:58:25 Models will be backed up to drive directory:\t./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22\n",
      "23:58:25 Models will be saved with base name:\tfnc-extension-v1_epoch[].pth\n",
      "23:58:25 Optimizers will be saved with base name:\tfnc-extension-v1_epoch[]_optimizer.pth\n",
      "23:58:25 Schedulers will be saved with base name:\tfnc-extension-v1_epoch[]_scheduler.pth\n",
      "23:58:25 Resuming training from epoch 3. Loading saved state from 2\n",
      "23:58:25 Loading model, optimizer, and scheduler from drive backup.\n",
      "23:58:25 Loading model, optimizer, and scheduler from drive backup.\n",
      "23:58:25 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0.pth\n",
      "23:58:25 Finished loading optimizer state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0_training.pth\n",
      "23:58:25 Finished loading scheduler state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0_training.pth\n",
      "23:58:25 Finished loading loss state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0_training.pth\n",
      "23:58:25 Performing initial evaluation...\n",
      "23:59:08 \t\tReconstruction\tDomain 0: 0.157\n",
      "23:59:08 \tMasked Prediction\tDomain 0: 0.157\n",
      "23:59:08 \tUnmasked Prediction\tDomain 0: 0.000\n",
      "23:59:08 Starting training from 3\n"
     ]
    }
   ],
   "source": [
    "eml.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iOQfJhKsYZi",
    "outputId": "fa3c88db-0c8a-45b9-f0ab-ca203a0b346a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:59:25 Saving model, optimizer, and scheduler.\n",
      "23:59:26 Performing drive backup of model, optimizer, and scheduler.\n"
     ]
    }
   ],
   "source": [
    "eml.trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rfjHQ0Osg5c",
    "outputId": "01a441f1-9e2c-4fbb-8ba0-cfdba6f097e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:00:11 \t\tReconstruction\tDomain 0: 0.157\n",
      "00:00:11 \tMasked Prediction\tDomain 0: 0.157\n",
      "00:00:11 \tUnmasked Prediction\tDomain 0: 0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, {'fnews': 2}, None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eml.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBwOfPCRsuvq"
   },
   "source": [
    "## 4.1.1. Deployment to generate training features\n",
    "Now we will use our trained LLM to generate the training features again.\n",
    "\n",
    "These features will be used to determine the best number of clusters and other hyperparameters. Subsequently, we can use our calculated hyperparameters to build a K-Means Clustering Plugin that includes a High-Density Set estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S10EGxFMkQWR"
   },
   "outputs": [],
   "source": [
    "! rm *.h5*\n",
    "! rm train-datashard-artifacts/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZBTqabVizdV"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "iJCi3pnLtDMk",
    "outputId": "f35b966c-646c-4283-d301-7fc95e1ee3d8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9T1XbZd0DOrO"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/extension/config.yml\"\n",
    "deploy = \"./EdnaML/profiles/FNC/extension/training_features.yml\"  # remove masking in data generation process\n",
    "crawler = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filtermask_generator = \"./EdnaML/profiles/FNC/fnc-filtermasked.py\"\n",
    "extension_model = \"./EdnaML/profiles/FNC/fnc-extension.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovIrGkTDtFiu",
    "outputId": "66231187-99e1-4a54-d028-2f80dd544247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
      "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
     ]
    }
   ],
   "source": [
    "ed = EdnaDeploy(config=config, deploy = deploy, dataloader_mode = \"train\", config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file)])\n",
    "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"feature_file\"] = \"%s-filtered-features\"%tweet_file\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jM7Ao46ZtFc1",
    "outputId": "de6cb7db-99a3-4b95-f8ff-a439600be961"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:14 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "00:19:14 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "00:19:14 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
      "00:19:14 Adding a model, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:941: UserWarning: keyvalue trainer in REGISTERED_EDNA_COMPONENTS <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'> is not available in self.decorator_reference. Not adding.\n",
      "  warnings.warn(\n",
      "00:19:14 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n",
      "00:19:14 ****************************************\n",
      "00:19:14 \n",
      "00:19:14 \n",
      "00:19:14 Using the following configuration:\n",
      "00:19:14 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "      train_file: tweets-2020-01-22-filtered.json\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: false\n",
      "      keyword_mask: false\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-unmasked-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS:\n",
      "    feature_file: tweets-2020-01-22-filtered-features\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: true\n",
      "      keyword_mask: true\n",
      "      keywords:\n",
      "      - covid\n",
      "      - corona\n",
      "      - mask\n",
      "      - wuhan\n",
      "      - n95\n",
      "      - sars\n",
      "      - monkey\n",
      "      - pandemic\n",
      "      - social\n",
      "      - quarantin\n",
      "      - virus\n",
      "      - infect\n",
      "      - lock\n",
      "      - ppe\n",
      "      - variant\n",
      "      - vaccine\n",
      "      - travel\n",
      "      - omicron\n",
      "      - ivermectin\n",
      "      - plandemic\n",
      "      - 5g\n",
      "      - gates\n",
      "      - hoax\n",
      "      - bioweapon\n",
      "      - bat\n",
      "      - fauci\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-filtermask-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 3\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - loss_class: CrossEntropyLoss\n",
      "    loss_kwargs:\n",
      "      ignore_index: -1\n",
      "  LABEL: mask_lm\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - TorchLoss\n",
      "  NAME: mask_lm\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCAlbertModeler\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN: {}\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: fnc-extension\n",
      "  MODEL_QUALIFIER: tweets-2020-01-22\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 5\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "00:19:14 \n",
      "00:19:14 \n",
      "00:19:14 ****************************************\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
      "  warnings.warn(\n",
      "00:19:14 Previous stop detected. Will attempt to resume from epoch 2, step 0\n",
      "00:19:14 Reading data with DataReader AlbertReader\n",
      "00:19:14 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "00:19:14 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "00:19:14 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "00:19:14 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
      "00:19:14 Updating CRAWLER to FNCCrawler\n",
      "00:19:14 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n",
      "00:19:14 https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz already exists at tweets-2020-01-22.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-filtermasked.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a trainer: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:14 Generating dataloader `FNCFilterMaskGenerator` with `train` mode\n",
      "00:19:14 Building Transforms\n",
      "00:19:17 Building Dataset\n",
      "00:19:17 Generating shards\n",
      "100%|██████████| 1/1 [00:14<00:00, 14.55s/it]\n",
      "00:19:31 Building Dataloader\n",
      "00:19:31 Generated test data/query generator\n",
      "00:19:31 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:32 Finished instantiating model with FNCAlbertModeler architecture\n",
      "00:19:32 Adding plugins after constructing model\n",
      "00:19:32 No saved model weights provided. Inferring weights path.\n",
      "00:19:32 Loading model from drive backup.\n",
      "00:19:32 Using weights from last saved epoch 2, at path None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:34 Model Summary retured the following error:\n",
      "00:19:34 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "00:19:34 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.add(crawler)\n",
    "ed.add(filtermask_generator)\n",
    "ed.add(extension_model)  # With model AND deployment defined\n",
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlsKtT7NzSEy",
    "outputId": "2c860af5-a64a-4872-f0c9-0e2cc03a65c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.deployment.edna_context.MODEL_HAS_LOADED_WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLotDqjQtFQg",
    "outputId": "0d325e73-165b-4283-9c86-57e90858f7c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:19:39 Starting deployment\n",
      "00:19:39 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
      "00:19:39 Loading a model from saved epoch 2, step 0\n",
      "00:19:39 Loading model from drive backup.\n",
      "00:19:39 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0.pth\n",
      "00:19:39 Looking for model plugins from drive backup.\n",
      "00:19:39 No plugin exists for name FastKMP-l2\n",
      "00:19:39 Loaded plugins from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
      "00:19:39 Setting up plugin hooks. Plugins will fire during:  always\n",
      "00:19:39 Executing deployment for  1 epochs\n",
      "00:19:39 Starting epoch 0\n",
      "00:21:11 Performing save at epoch 1\n",
      "00:21:11 Saving model plugins.\n",
      "00:21:11 No plugins to save\n",
      "00:21:11 Executing end of epoch steps\n",
      "00:21:11 Completed deployment task.\n"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "gmSTh7jcDRfi",
    "outputId": "820d44fe-bd38-41a8-a6e3-982ea79d35d9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'fnc-extension-v1-albert-tweets-2020-01-22'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed.saveMetadata.MODEL_SAVE_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PphaBtY5DRdV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhDlXyQDDRbG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBH_VHmGAqbX"
   },
   "source": [
    "## 4.2 Estimating best number of clusters from the BERT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLHxGtD9JPDZ"
   },
   "outputs": [],
   "source": [
    "def cluster_sweep(features_file, batch_size, max_iters, cluster_range):\n",
    "  import h5py, time\n",
    "  from sklearn.cluster import MiniBatchKMeans\n",
    "  inertia = []\n",
    "  data = h5py.File(features_file, 'r')\n",
    "  data_size = data['features'].shape[0]\n",
    "\n",
    "  for k in cluster_range:\n",
    "    print(\"Starting sweep for k={kval}, with {iters} iterations\".format(kval=k, iters=max_iters))\n",
    "    kmeans = MiniBatchKMeans(n_clusters = k, random_state = 23465356, batch_size = batch_size)\n",
    "    stime = time.time()\n",
    "    for iters in range(max_iters):\n",
    "      for i in range(0, data_size, batch_size):\n",
    "          current_data = data['features'][i:i+batch_size]\n",
    "          kmeans.partial_fit(current_data)\n",
    "      if iters%5 == 0:\n",
    "        etime = round(time.time() - stime, 2)\n",
    "        print(\"\\t[{elapse} s] -- Completed {iters} iterations\".format(iters=iters, elapse = etime))\n",
    "        stime = time.time()\n",
    "    print(\"\\tCompeted MBKM for k={kval}, with inertia: {inertia}\".format(kval=k, inertia = kmeans.inertia_))\n",
    "    inertia.append(kmeans.inertia_)\n",
    "  return inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnHgqBPoJPBB",
    "outputId": "ebbe400d-4e4a-4edd-a776-bbc728a38780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sweep for k=10, with 25 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[0.95 s] -- Completed 0 iterations\n",
      "\t[4.02 s] -- Completed 5 iterations\n",
      "\t[3.02 s] -- Completed 10 iterations\n",
      "\t[2.69 s] -- Completed 15 iterations\n",
      "\t[2.72 s] -- Completed 20 iterations\n",
      "\tCompeted MBKM for k=10, with inertia: 14.719842910766602\n",
      "Starting sweep for k=20, with 25 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[0.78 s] -- Completed 0 iterations\n",
      "\t[3.94 s] -- Completed 5 iterations\n",
      "\t[3.18 s] -- Completed 10 iterations\n",
      "\t[2.72 s] -- Completed 15 iterations\n",
      "\t[2.71 s] -- Completed 20 iterations\n",
      "\tCompeted MBKM for k=20, with inertia: 10.361695289611816\n",
      "Starting sweep for k=50, with 25 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[0.66 s] -- Completed 0 iterations\n",
      "\t[4.1 s] -- Completed 5 iterations\n",
      "\t[3.36 s] -- Completed 10 iterations\n",
      "\t[2.85 s] -- Completed 15 iterations\n",
      "\t[2.83 s] -- Completed 20 iterations\n",
      "\tCompeted MBKM for k=50, with inertia: 7.377807140350342\n",
      "Starting sweep for k=100, with 25 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[0.91 s] -- Completed 0 iterations\n",
      "\t[4.46 s] -- Completed 5 iterations\n",
      "\t[3.41 s] -- Completed 10 iterations\n",
      "\t[3.0 s] -- Completed 15 iterations\n",
      "\t[2.98 s] -- Completed 20 iterations\n",
      "\tCompeted MBKM for k=100, with inertia: 5.764917373657227\n"
     ]
    }
   ],
   "source": [
    "cluster_range = [10,20,50,100]\n",
    "inertia = cluster_sweep(\n",
    "    features_file = \"%s-filtered-features.h5\"%tweet_file,\n",
    "    batch_size=256,\n",
    "    max_iters = 25,\n",
    "    cluster_range = cluster_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYUA2w_dI7fd"
   },
   "outputs": [],
   "source": [
    "# In case of interruptions or crashes...\n",
    "#inertia2 = [1660, 5510, 3100, 2290] + inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "0CArQNFjZRzT",
    "outputId": "99f7dc5f-7058-4460-f1b6-336bdc664b62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-1a0de2428c2d>:4: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(x=\"cluster_range\", y=\"inertia\", data=pd.DataFrame(list(zip(inertia, cluster_range)), columns=[\"inertia\", \"cluster_range\"]),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Elbow Plot for KMeans')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.lineplot(x=\"cluster_range\", y=\"inertia\", data=pd.DataFrame(list(zip(inertia, cluster_range)), columns=[\"inertia\", \"cluster_range\"]),\n",
    "             palette=\"tab10\", linewidth=2.5, marker=\"o\", markersize=10). \\\n",
    "              set(title=\"Elbow Plot for KMeans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3fIovF-rCHb"
   },
   "source": [
    "So, we find here that for FNC Jan 2020 that **40 PROXIES** fits the elbow visual test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ngojQFRWcf9"
   },
   "outputs": [],
   "source": [
    "proxy = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EU53fUFKuFEb"
   },
   "source": [
    "## 4.3 Generate Plugins\n",
    "\n",
    "Using k=20 proxies, we will now generate the FastKMeans Plugin for our LLM for this FNC window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bqinEpfXHCD7"
   },
   "outputs": [],
   "source": [
    "!rm -rf -- train-datashard-artifacts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tc1Iz_XU84Ia",
    "outputId": "854a92fd-fac5-4ace-9b85-8375836650e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "GDroKNDP84Ia",
    "outputId": "6f8074ec-3b81-41d8-a7da-ad9f252f6e0e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3kmromk84Ib"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/extension/config.yml\"\n",
    "deploy = \"./EdnaML/profiles/FNC/extension/fastkmeans.yml\" #basically, set up plugin info, and remove masking\n",
    "crawler = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filtermask_generator = \"./EdnaML/profiles/FNC/fnc-filtermasked.py\"\n",
    "extension_model = \"./EdnaML/profiles/FNC/fnc-extension.py\"\n",
    "fastkmeans = \"./EdnaML/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5vnq4uJ84Ib",
    "outputId": "f18b1ae1-3e62-48d0-afd5-701a82445e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
      "Injected key-value pair:  SAVE.SAVE_FREQUENCY, 1\n",
      "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
     ]
    }
   ],
   "source": [
    "ed = EdnaDeploy(config=config, deploy = deploy, dataloader_mode = \"train\", config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.SAVE_FREQUENCY\", 1)])\n",
    "#ed = EdnaDeploy(config=config,  dataloader_mode = \"train\", config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.SAVE_FREQUENCY\", 1)])\n",
    "\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"train_file\"] = \"%s-filtered.json\"%tweet_file\n",
    "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bmlZV-sy84Ib",
    "outputId": "dd137f64-1cb8-4f47-feb2-077ce347e33c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:14 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "00:24:14 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "00:24:14 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
      "00:24:14 Adding a model, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
      "00:24:14 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n",
      "00:24:14 Adding a model_plugin, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
      "00:24:14 Adding a model_plugin, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
      "00:24:14 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FNCPluginDeployment\n",
      "00:24:14 ****************************************\n",
      "00:24:14 \n",
      "00:24:14 \n",
      "00:24:14 Using the following configuration:\n",
      "00:24:14 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "      train_file: tweets-2020-01-22-filtered.json\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: false\n",
      "      keyword_mask: false\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-unmasked-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS: {}\n",
      "  PLUGIN:\n",
      "    HOOKS: warmup\n",
      "    RESET: true\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: true\n",
      "      keyword_mask: true\n",
      "      keywords:\n",
      "      - covid\n",
      "      - corona\n",
      "      - mask\n",
      "      - wuhan\n",
      "      - n95\n",
      "      - sars\n",
      "      - monkey\n",
      "      - pandemic\n",
      "      - social\n",
      "      - quarantin\n",
      "      - virus\n",
      "      - infect\n",
      "      - lock\n",
      "      - ppe\n",
      "      - variant\n",
      "      - vaccine\n",
      "      - travel\n",
      "      - omicron\n",
      "      - ivermectin\n",
      "      - plandemic\n",
      "      - 5g\n",
      "      - gates\n",
      "      - hoax\n",
      "      - bioweapon\n",
      "      - bat\n",
      "      - fauci\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-filtermask-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 3\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - loss_class: CrossEntropyLoss\n",
      "    loss_kwargs:\n",
      "      ignore_index: -1\n",
      "  LABEL: mask_lm\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - TorchLoss\n",
      "  NAME: mask_lm\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCAlbertModeler\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN:\n",
      "  FastKMP-l2:\n",
      "    PLUGIN: FastKMP\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.5\n",
      "      batch_size: 256\n",
      "      dimensions: 768\n",
      "      dist: euclidean\n",
      "      iterations: 30\n",
      "      proxies: 40\n",
      "    PLUGIN_NAME: FastKMP-l2\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: fnc-extension\n",
      "  MODEL_QUALIFIER: tweets-2020-01-22\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 5\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "00:24:14 \n",
      "00:24:14 \n",
      "00:24:14 ****************************************\n",
      "00:24:15 Previous stop detected. Will attempt to resume from epoch 2, step 0\n",
      "00:24:15 Reading data with DataReader AlbertReader\n",
      "00:24:15 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "00:24:15 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "00:24:15 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "00:24:15 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
      "00:24:15 Updating CRAWLER to FNCCrawler\n",
      "00:24:15 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz\n",
      "00:24:15 https://ednadatasets.blob.core.windows.net/edna-covid-raw/tweets-2020-01-22.json.gz already exists at tweets-2020-01-22.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-filtermasked.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a trainer: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a model_plugin: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FastKMP'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FNCPluginDeployment'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:15 Generating dataloader `FNCFilterMaskGenerator` with `train` mode\n",
      "00:24:15 Building Transforms\n",
      "00:24:16 Building Dataset\n",
      "00:24:16 Generating shards\n",
      "100%|██████████| 1/1 [00:16<00:00, 16.91s/it]\n",
      "00:24:33 Building Dataloader\n",
      "00:24:33 Generated test data/query generator\n",
      "00:24:33 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:33 Finished instantiating model with FNCAlbertModeler architecture\n",
      "00:24:33 Adding plugins after constructing model\n",
      "00:24:33 Added plugin FastKMP-l2\n",
      "00:24:33 No saved model weights provided. Inferring weights path.\n",
      "00:24:33 Loading model from drive backup.\n",
      "00:24:33 Using weights from last saved epoch 2, at path None.\n",
      "00:24:33 Model Summary retured the following error:\n",
      "00:24:33 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "00:24:33 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n",
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.add(crawler)\n",
    "ed.add(filtermask_generator)\n",
    "ed.add(extension_model)  # With model AND deployment defined\n",
    "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UD7rmlAG84Ib",
    "outputId": "25caab91-98a6-4a84-adc2-ae46beb9d602"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:24:46 Starting deployment\n",
      "00:24:46 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
      "00:24:46 Loading a model from saved epoch 2, step 0\n",
      "00:24:46 Loading model from drive backup.\n",
      "00:24:46 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0.pth\n",
      "00:24:46 Looking for model plugins from drive backup.\n",
      "00:24:46 Loading plugin with name FastKMP-l2\n",
      "00:24:46 Loaded plugins from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
      "00:24:46 Setting up plugin hooks. Plugins will fire during:  warmup\n",
      "00:24:46 Executing deployment for  1 epochs\n",
      "00:24:46 Starting epoch 0\n",
      "00:26:12 Performing save at epoch 1\n",
      "00:26:12 Saving model plugins.\n",
      "00:26:12 Saved plugins: dict_keys(['FastKMP-l2'])\n",
      "00:26:12 Performing drive backup of model plugins\n",
      "00:26:12 Executing end of epoch steps\n",
      "00:26:12 Completed deployment task.\n"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WETqeAOTuoGl"
   },
   "source": [
    "## 4.4 Apply Plugin to Generate Neighbors\n",
    "\n",
    "Now we will use our generated plugin to determine which members of fns-unfiltered should belong in fnc-filtered because they are neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dw555d1N90KW"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Df3g-6C590KX",
    "outputId": "f0066b57-9a14-4f03-c186-db04a8d031d0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ax2DiUM90KX"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/extension/config.yml\"\n",
    "deploy = \"./EdnaML/profiles/FNC/extension/neighbors.yml\" #basically, set up plugin info, and remove masking\n",
    "crawler = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filtermask_generator = \"./EdnaML/profiles/FNC/fnc-filtermasked.py\"\n",
    "extension_model = \"./EdnaML/profiles/FNC/fnc-extension.py\"\n",
    "fastkmeans = \"./EdnaML/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin\n",
    "neighbors = \"./EdnaML/profiles/FNC/fnc-neighbors.py\"  # contains deployment for neighbors generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWGSD2pG90KX",
    "outputId": "73b06413-4c7f-440a-d68d-a2ab40b735a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
      "Injected key-value pair:  SAVE.DRIVE_BACKUP, True\n",
      "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
     ]
    }
   ],
   "source": [
    "ed = EdnaDeploy(config=config, deploy = deploy, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.DRIVE_BACKUP\", True)])\n",
    "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file  # deployment will generate twt-neighbors.json\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-unfiltered.json\"%tweet_file\n",
    "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGVhF39190KX",
    "outputId": "172ff31a-b7c8-4654-9d04-9e401b4fad8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:04 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "00:28:04 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "00:28:04 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
      "00:28:04 Adding a model, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:941: UserWarning: keyvalue trainer in REGISTERED_EDNA_COMPONENTS <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'> is not available in self.decorator_reference. Not adding.\n",
      "  warnings.warn(\n",
      "00:28:04 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-filtermasked.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a trainer: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:04 Adding a model_plugin, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
      "00:28:04 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FNCPluginDeployment\n",
      "00:28:04 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-neighbors.py, with inferred name FNCPluginDeployment\n",
      "00:28:04 ****************************************\n",
      "00:28:04 \n",
      "00:28:04 \n",
      "00:28:04 Using the following configuration:\n",
      "00:28:04 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "      test_file: tweets-2020-01-22-unfiltered.json\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: false\n",
      "      keyword_mask: false\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-unmasked-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS:\n",
      "    basename: tweets-2020-01-22\n",
      "    neighbor_output: neighbor\n",
      "    unfiltered_output: unfiltered\n",
      "  PLUGIN:\n",
      "    HOOKS: activated\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: true\n",
      "      keyword_mask: true\n",
      "      keywords:\n",
      "      - covid\n",
      "      - corona\n",
      "      - mask\n",
      "      - wuhan\n",
      "      - n95\n",
      "      - sars\n",
      "      - monkey\n",
      "      - pandemic\n",
      "      - social\n",
      "      - quarantin\n",
      "      - virus\n",
      "      - infect\n",
      "      - lock\n",
      "      - ppe\n",
      "      - variant\n",
      "      - vaccine\n",
      "      - travel\n",
      "      - omicron\n",
      "      - ivermectin\n",
      "      - plandemic\n",
      "      - 5g\n",
      "      - gates\n",
      "      - hoax\n",
      "      - bioweapon\n",
      "      - bat\n",
      "      - fauci\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-filtermask-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 3\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - loss_class: CrossEntropyLoss\n",
      "    loss_kwargs:\n",
      "      ignore_index: -1\n",
      "  LABEL: mask_lm\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - TorchLoss\n",
      "  NAME: mask_lm\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCAlbertModeler\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN:\n",
      "  FastKMP-l2:\n",
      "    PLUGIN: FastKMP\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.5\n",
      "      batch_size: 256\n",
      "      dimensions: 768\n",
      "      dist: euclidean\n",
      "      iterations: 30\n",
      "      proxies: 40\n",
      "    PLUGIN_NAME: FastKMP-l2\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: fnc-extension\n",
      "  MODEL_QUALIFIER: tweets-2020-01-22\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 5\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "00:28:04 \n",
      "00:28:04 \n",
      "00:28:04 ****************************************\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
      "  warnings.warn(\n",
      "00:28:04 Previous stop detected. Will attempt to resume from epoch 2, step 0\n",
      "00:28:04 Reading data with DataReader AlbertReader\n",
      "00:28:04 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "00:28:04 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "00:28:04 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "00:28:04 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
      "00:28:04 Updating CRAWLER to FNCCrawler\n",
      "00:28:04 Generating dataloader `FNCFilterMaskGenerator` with `test` mode\n",
      "00:28:04 Building Transforms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a model_plugin: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FastKMP'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FNCPluginDeployment'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-neighbors.py.FNCPluginDeployment'>, from file: /content/EdnaML/profiles/FNC/fnc-neighbors.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:06 Building Dataset\n",
      "00:28:06 Building Dataloader\n",
      "00:28:06 Generated test data/query generator\n",
      "00:28:06 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:07 Finished instantiating model with FNCAlbertModeler architecture\n",
      "00:28:07 Adding plugins after constructing model\n",
      "00:28:07 Added plugin FastKMP-l2\n",
      "00:28:07 No saved model weights provided. Inferring weights path.\n",
      "00:28:07 Loading model from drive backup.\n",
      "00:28:07 Using weights from last saved epoch 2, at path None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:08 Model Summary retured the following error:\n",
      "00:28:08 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "00:28:08 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.add(crawler)\n",
    "ed.add(filtermask_generator)\n",
    "ed.add(extension_model)  # With model AND deployment defined\n",
    "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
    "ed.add(neighbors)\n",
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mnu-Q77o90KX",
    "outputId": "c943ee31-c7cb-4349-c3e9-5241a4402aae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:28:19 Starting deployment\n",
      "00:28:19 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
      "00:28:19 Loading a model from saved epoch 2, step 0\n",
      "00:28:19 Loading model from drive backup.\n",
      "00:28:19 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0.pth\n",
      "00:28:19 Looking for model plugins from drive backup.\n",
      "00:28:19 Loading plugin with name FastKMP-l2\n",
      "00:28:19 Loaded plugins from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
      "00:28:19 Setting up plugin hooks. Plugins will fire during:  activated\n",
      "00:28:19 Executing deployment for  1 epochs\n",
      "00:28:19 Starting epoch 0\n",
      "00:29:01 Performing save at epoch 1\n",
      "00:29:01 Saving model plugins.\n",
      "00:29:01 Saved plugins: dict_keys(['FastKMP-l2'])\n",
      "00:29:01 Performing drive backup of model plugins\n",
      "00:29:01 Executing end of epoch steps\n",
      "00:29:01 Completed deployment task.\n"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rmrRbkmCzBW"
   },
   "source": [
    "## 4.5. Generating FNC-Extended = FNC-Filtered + FNC-Neighbors\n",
    "\n",
    "Here, we combine fnc-filtered.json and fnc-neighbors.json to create fnc-extended.json. Then we upload this to our azure blob for this month!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6duv7zdvBR5",
    "outputId": "190c04f4-2b98-4fec-ad1e-98920c66ecf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- STATISTICS ------------\n",
      "\n",
      "ORIGINAL    24052\n",
      "FILTERED    17718\n",
      "UNFILTERED  6333\n",
      "NEIGHBORS   220\n",
      "\n",
      "EXTENSION   1.24%\n",
      "LIFT        3.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original = sum(1 for line in open(\"%s.json\"%tweet_file))\n",
    "filtered = sum(1 for line in open(\"%s-filtered.json\"%tweet_file))\n",
    "unfiltered = sum(1 for line in open(\"%s-unfiltered.json\"%tweet_file))\n",
    "neighbor = sum(1 for line in open(\"%s-neighbor.json\"%tweet_file))\n",
    "extension = 100 * neighbor / filtered\n",
    "lift = 100 * neighbor / unfiltered\n",
    "print(\n",
    "\"\"\"\n",
    "-------- STATISTICS ------------\n",
    "\n",
    "ORIGINAL    {original}\n",
    "FILTERED    {filtered}\n",
    "UNFILTERED  {unfiltered}\n",
    "NEIGHBORS   {neighbor}\n",
    "\n",
    "EXTENSION   {extension}%\n",
    "LIFT        {lift}%\n",
    "\"\"\".format(original=original, filtered=filtered, unfiltered=unfiltered, neighbor=neighbor, extension=round(extension,2), lift=round(lift,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTCXrZ8ZBDYA"
   },
   "outputs": [],
   "source": [
    "cat \"$tweet_file-filtered.json\" \"$tweet_file-neighbor.json\" >> \"$tweet_file-extended.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMcmognzvBq2"
   },
   "source": [
    "## 4.6. Generate FNC-Extended-Oracle-Unlabeled, and upload\n",
    "\n",
    "Here, we will randomly select ~500 points to perform manual labeling. We will try to select these points from each cluster of our FNC LLM Model.\n",
    "\n",
    "Specifically, we will first use our existing plugin to compute the distances of each point in the extension to its cluster center, as well as its cluster index (the index itself is not semantic).\n",
    "\n",
    "After the deployment is complete, we will sweep across the data to find, for each cluster, the closest point, as well as some points further away to generate a more complete representation. That is, since we have 20 clusters (in FNC Jan), and require 500 points, for each cluster we can bin  into 24 regions + closest, and from the 24 regions, select one point at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipXmrO-NEmVj"
   },
   "outputs": [],
   "source": [
    "#!wget https://ednadatasets.blob.core.windows.net/edna-covid-extended/$tweet_file-extended.json.gz\n",
    "#!gunzip $tweet_file-extended.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dj8EL-WQNMLk",
    "outputId": "134adb84-212a-4bdb-9ff5-af36a02c482a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "6mgUBMCkNMLl",
    "outputId": "80ca59bd-ad67-4fb0-9182-b68dc701532a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.0.1+cu118'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfoqPP8ONMLl"
   },
   "outputs": [],
   "source": [
    "config = \"./EdnaML/profiles/FNC/extension/config.yml\"\n",
    "deploy = \"./EdnaML/profiles/FNC/extension/oracle.yml\" #basically, set up plugin info, and remove masking; shuffle, and set up the inputs for oracle file generation\n",
    "crawler = \"./EdnaML/profiles/FNC/fnc-crawler.py\"\n",
    "filtermask_generator = \"./EdnaML/profiles/FNC/fnc-filtermasked.py\"\n",
    "extension_model = \"./EdnaML/profiles/FNC/fnc-extension.py\"\n",
    "fastkmeans = \"./EdnaML/profiles/FNC/fnc-fastkmeans.py\"  # contains plugin and deployment for the plugin\n",
    "oracle = \"./EdnaML/profiles/FNC/fnc-oracle.py\"  # contains deployment for oracle selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9RNyuhBVNMLl",
    "outputId": "7875bd72-17b2-415c-fe00-be006a529dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, tweets-2020-01-22\n",
      "Injected key-value pair:  SAVE.DRIVE_BACKUP, True\n",
      "Log file exists at fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1-albert-tweets-2020-01-22-logger.log. Will attempt to append there.\n"
     ]
    }
   ],
   "source": [
    "ed = EdnaDeploy(config=config, deploy = deploy, config_inject=[(\"SAVE.MODEL_QUALIFIER\", tweet_file), (\"SAVE.DRIVE_BACKUP\", True)])\n",
    "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"basename\"] = \"%s\"%tweet_file\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"test_file\"] = \"%s-extended.json\"%tweet_file\n",
    "ed.cfg.MODEL_PLUGIN[\"FastKMP-l2\"].PLUGIN_KWARGS[\"proxies\"] = proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FjJqrMnZNMLl",
    "outputId": "19f86332-0fd0-44ca-d245-1fc047a5fc7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:31:39 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCCrawler\n",
      "00:31:39 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-crawler.py, with inferred name FNCRawGenerator\n",
      "00:31:39 Adding a generator, from /content/EdnaML/profiles/FNC/fnc-filtermasked.py, with inferred name FNCFilterMaskGenerator\n",
      "00:31:39 Adding a model, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCAlbertModeler\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:941: UserWarning: keyvalue trainer in REGISTERED_EDNA_COMPONENTS <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'> is not available in self.decorator_reference. Not adding.\n",
      "  warnings.warn(\n",
      "00:31:39 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-extension.py, with inferred name FNCTrainingFeaturesDeploy\n",
      "00:31:40 Adding a model_plugin, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FastKMP\n",
      "00:31:40 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-fastkmeans.py, with inferred name FNCPluginDeployment\n",
      "00:31:40 Adding a deployment, from /content/EdnaML/profiles/FNC/fnc-oracle.py, with inferred name FNCOracleBinning\n",
      "00:31:40 ****************************************\n",
      "00:31:40 \n",
      "00:31:40 \n",
      "00:31:40 Using the following configuration:\n",
      "00:31:40 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "      test_file: tweets-2020-01-22-extended.json\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: false\n",
      "      keyword_mask: false\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-extended-unmasked-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS:\n",
      "    basename: tweets-2020-01-22\n",
      "    extended_output: extended\n",
      "    oracle_output: oracle\n",
      "  PLUGIN:\n",
      "    HOOKS: activated\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-raw\n",
      "      azfile: tweets-2020-01-22.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: true\n",
      "      keyword_mask: true\n",
      "      keywords:\n",
      "      - covid\n",
      "      - corona\n",
      "      - mask\n",
      "      - wuhan\n",
      "      - n95\n",
      "      - sars\n",
      "      - monkey\n",
      "      - pandemic\n",
      "      - social\n",
      "      - quarantin\n",
      "      - virus\n",
      "      - infect\n",
      "      - lock\n",
      "      - ppe\n",
      "      - variant\n",
      "      - vaccine\n",
      "      - travel\n",
      "      - omicron\n",
      "      - ivermectin\n",
      "      - plandemic\n",
      "      - 5g\n",
      "      - gates\n",
      "      - hoax\n",
      "      - bioweapon\n",
      "      - bat\n",
      "      - fauci\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-filtermask-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 3\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - loss_class: CrossEntropyLoss\n",
      "    loss_kwargs:\n",
      "      ignore_index: -1\n",
      "  LABEL: mask_lm\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - TorchLoss\n",
      "  NAME: mask_lm\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: FNCAlbertModeler\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN:\n",
      "  FastKMP-l2:\n",
      "    PLUGIN: FastKMP\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.5\n",
      "      batch_size: 256\n",
      "      dimensions: 768\n",
      "      dist: euclidean\n",
      "      iterations: 30\n",
      "      proxies: 40\n",
      "    PLUGIN_NAME: FastKMP-l2\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: fnc-extension\n",
      "  MODEL_QUALIFIER: tweets-2020-01-22\n",
      "  MODEL_VERSION: 1\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 5\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "00:31:40 \n",
      "00:31:40 \n",
      "00:31:40 ****************************************\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:222: UserWarning: Mode is `test` but weights is `None`. This will cause issues when EdnaML attempts to load weights\n",
      "  warnings.warn(\n",
      "00:31:40 Previous stop detected. Will attempt to resume from epoch 2, step 0\n",
      "00:31:40 Reading data with DataReader AlbertReader\n",
      "00:31:40 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "00:31:40 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "00:31:40 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "00:31:40 Updating GENERATOR to queued class FNCFilterMaskGenerator\n",
      "00:31:40 Updating CRAWLER to FNCCrawler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-crawler.py.FNCRawGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-crawler.py\n",
      "Registering a generator: <class './EdnaML/profiles/FNC/fnc-filtermasked.py.FNCFilterMaskGenerator'>, from file: /content/EdnaML/profiles/FNC/fnc-filtermasked.py\n",
      "Registering a model: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModeler'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a trainer: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCAlbertModelerTrainer'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-extension.py.FNCTrainingFeaturesDeploy'>, from file: /content/EdnaML/profiles/FNC/fnc-extension.py\n",
      "Registering a model_plugin: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FastKMP'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-fastkmeans.py.FNCPluginDeployment'>, from file: /content/EdnaML/profiles/FNC/fnc-fastkmeans.py\n",
      "Registering a deployment: <class './EdnaML/profiles/FNC/fnc-oracle.py.FNCOracleBinning'>, from file: /content/EdnaML/profiles/FNC/fnc-oracle.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:31:40 Generating dataloader `FNCFilterMaskGenerator` with `test` mode\n",
      "00:31:40 Building Transforms\n",
      "00:31:42 Building Dataset\n",
      "00:31:42 Building Dataloader\n",
      "00:31:42 Generated test data/query generator\n",
      "00:31:42 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:31:43 Finished instantiating model with FNCAlbertModeler architecture\n",
      "00:31:43 Adding plugins after constructing model\n",
      "00:31:43 Added plugin FastKMP-l2\n",
      "00:31:43 No saved model weights provided. Inferring weights path.\n",
      "00:31:43 Loading model from drive backup.\n",
      "00:31:43 Using weights from last saved epoch 2, at path None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:31:45 Model Summary retured the following error:\n",
      "00:31:45 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "00:31:45 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.add(crawler)\n",
    "ed.add(filtermask_generator)\n",
    "ed.add(extension_model)  # With model AND deployment defined\n",
    "ed.add(fastkmeans)  # # With plugin AND deployment defined; deployment replaces prior\n",
    "ed.add(oracle)\n",
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RmtVr6ljwF6-",
    "outputId": "c3a68fe7-dcb1-4a00-e3a4-43b221504108"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00:31:48 Starting deployment\n",
      "00:31:48 Logging to:\tfnc-extension-v1-albert-tweets-2020-01-22-logger.log\n",
      "00:31:48 Loading a model from saved epoch 2, step 0\n",
      "00:31:48 Loading model from drive backup.\n",
      "00:31:49 Finished loading model state_dict from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_epoch2_step0.pth\n",
      "00:31:49 Looking for model plugins from drive backup.\n",
      "00:31:49 Loading plugin with name FastKMP-l2\n",
      "00:31:49 Loaded plugins from ./drive/MyDrive/Projects/FNC/Models/fnc-extension-v1-albert-tweets-2020-01-22/fnc-extension-v1_plugins.pth\n",
      "00:31:49 Setting up plugin hooks. Plugins will fire during:  activated\n",
      "00:31:49 Executing deployment for  1 epochs\n",
      "00:31:49 Starting epoch 0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7e5cc19c5c24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/EdnaML/src/ednaml/core/EdnaDeploy.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_stop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildDeployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/EdnaML/src/ednaml/deploy/BaseDeploy.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, continue_epoch, continue_step, inference, ignore_plugins, execute, model_build)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting epoch %i\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_epoch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_epoch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/EdnaML/src/ednaml/deploy/BaseDeploy.py\u001b[0m in \u001b[0;36mdata_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             for batch in tqdm.tqdm(\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             ):    \n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/./EdnaML/profiles/FNC/fnc-filtermasked.py\", line 326, in __getitem__\n    return self.getter(idx)\n  File \"/content/./EdnaML/profiles/FNC/fnc-filtermasked.py\", line 143, in shardget\n    self.sharded_dataset = self.load_shard(self.shard_shuffle[self.shard_load_index])\n  File \"/content/./EdnaML/profiles/FNC/fnc-filtermasked.py\", line 242, in load_shard\n    return torch.load(shard_save_path)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 791, in load\n    with _open_file_like(f, 'rb') as opened_file:\n  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 271, in _open_file_like\n    return _open_file(name_or_buffer, mode)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 252, in __init__\n    super().__init__(open(name, mode))\nFileNotFoundError: [Errno 2] No such file or directory: 'test-datashard-artifacts/fnc-extended-unmasked-shard-1.pt'\n"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5ADOWKGvn4Y"
   },
   "source": [
    "## 4.7 Upload to azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bPh8p_h31nz"
   },
   "source": [
    "https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python?tabs=environment-variable-windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aou8Ri3YQ-Tb"
   },
   "outputs": [],
   "source": [
    "!gzip $tweet_file-oracle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzltNT_GoiWh"
   },
   "outputs": [],
   "source": [
    "!gunzip $tweet_file-extended.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DEardAhSiAW"
   },
   "outputs": [],
   "source": [
    "!gzip $tweet_file-extended.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFjGRDua2SSJ"
   },
   "outputs": [],
   "source": [
    "!pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJ29pqNr3Edi"
   },
   "outputs": [],
   "source": [
    "import os, uuid\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__\n",
    "\n",
    "print(\"Azure Blob Storage v\" + __version__ + \" - Python quickstart sample\")\n",
    "connect_str = \"<AZURE_STORAGE_CONNECTION_STRING>\"\n",
    "# Create the BlobServiceClient object which will be used to create a container client\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
    "\n",
    "extended_file = \"%s-extended.json.gz\"%tweet_file\n",
    "oracle_file = \"%s-oracle.json.gz\"%tweet_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6eYqvpq5fKD"
   },
   "outputs": [],
   "source": [
    "# Create a unique name for the container\n",
    "container_name = \"edna-covid-extended\"\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=extended_file)\n",
    "with open(extended_file, \"rb\") as data:\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZ1GG6he5cuf"
   },
   "outputs": [],
   "source": [
    "# Create a unique name for the container\n",
    "container_name = \"edna-covid-extended-oracle\"\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=oracle_file)\n",
    "with open(oracle_file, \"rb\") as data:\n",
    "    blob_client.upload_blob(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIFGY3uogZiS",
    "outputId": "18906be0-d724-4bc9-e66c-6ae85b49c17c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class '__main__.NELACrawler'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Registering a model: <class '__main__.NELAModel'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Registering a trainer: <class '__main__.NELATrainer'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/profiles/NELA/nela.py\", line 331, in <module>\n",
      "    main()\n",
      "TypeError: main() missing 2 required positional arguments: 'config' and 'mode'\n"
     ]
    }
   ],
   "source": [
    "  !python /content/EdnaML/profiles/NELA/nela.py nela-covid-v0.yml test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBRz9opTpPq1"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/train-datashard-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CL4780q_nPJs",
    "outputId": "a7ab2a78-941e-42d2-dd78-8a4071adda23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering a crawler: <class '__main__.NELACrawler'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Registering a model: <class '__main__.NELAModel'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Registering a trainer: <class '__main__.NELATrainer'>, from file: /content/EdnaML/profiles/NELA/nela.py\n",
      "Log file exists at nela-v5-albert-covid20/nela-v5-albert-covid20-logger.log. Will attempt to append there.\n",
      "20:35:15 ****************************************\n",
      "20:35:15 \n",
      "20:35:15 \n",
      "20:35:15 Using the following configuration:\n",
      "20:35:15 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS: {}\n",
      "    DATAREADER: DataReader\n",
      "    DATASET_ARGS: {}\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS: {}\n",
      "  DEPLOY: BaseDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS: {}\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      data_folder: Data\n",
      "      sub_folder: nela-covid-2020\n",
      "    DATAREADER: AlbertReader\n",
      "    DATASET_ARGS:\n",
      "      classificationclass:\n",
      "      - reliability\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.2\n",
      "      shardcache: true\n",
      "      shardsize: 20000\n",
      "      shuffle: true\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      do_lower_case: true\n",
      "      spm_model_file: 30k-clean.model\n",
      "      tokenizer: AlbertFullTokenizer\n",
      "      vocab_file: 30k-clean.vocab\n",
      "  EPOCHS: 15\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 8\n",
      "LOGGING:\n",
      "  INPUT_SIZE: null\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS:\n",
      "- KWARGS:\n",
      "  - {}\n",
      "  LABEL: reliability\n",
      "  LAMBDAS:\n",
      "  - 1.0\n",
      "  LOSSES:\n",
      "  - SoftmaxLogitsLoss\n",
      "  NAME: classification\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: NELA\n",
      "  MODEL_BASE: Albert\n",
      "  MODEL_KWARGS:\n",
      "    attention_probs_dropout_prob: 0\n",
      "    embedding_size: 128\n",
      "    hidden_act: gelu_new\n",
      "    hidden_dropout_prob: 0\n",
      "    hidden_size: 768\n",
      "    initializer_range: 0.02\n",
      "    inner_group_num: 1\n",
      "    intermediate_size: 3072\n",
      "    layer_norm_eps: 1.0e-12\n",
      "    max_position_embeddings: 512\n",
      "    num_attention_heads: 12\n",
      "    num_hidden_groups: 1\n",
      "    num_hidden_layers: 12\n",
      "    pooling: pooled\n",
      "    type_vocab_size: 2\n",
      "    vocab_size_or_config_json_file: 30000\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN: {}\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 1.0e-05\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: AdamW\n",
      "  OPTIMIZER_KWARGS:\n",
      "    eps: 1.0e-06\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/NELA/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert\n",
      "  MODEL_CORE_NAME: nela\n",
      "  MODEL_QUALIFIER: covid20\n",
      "  MODEL_VERSION: 5\n",
      "  SAVE_FREQUENCY: 1\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    gamma: 0.5\n",
      "    step_size: 3\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 128\n",
      "  WORKERS: 2\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 128\n",
      "  WORKERS: 2\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "20:35:15 \n",
      "20:35:15 \n",
      "20:35:15 ****************************************\n",
      "/content/EdnaML/src/ednaml/core/EdnaML.py:249: UserWarning: Model Albert is not available. Please choose one of the following: dict_keys(['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2', 'resnet18_cbam', 'resnet34_cbam', 'resnet50_cbam', 'resnet101_cbam', 'resnet152_cbam', 'shufflenetv2_small']) if you want to load pretrained weights\n",
      "  warnings.warn(\n",
      "20:35:15 No previous stop detected. Will start from epoch 0\n",
      "20:35:15 Loaded BaseStorage from ednaml.storage to build Storage\n",
      "20:35:15 Reading data with DataReader AlbertReader\n",
      "20:35:15 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "20:35:15 Default DATASET is <class 'ednaml.generators.AlbertGenerator.AlbertDataset'>\n",
      "20:35:15 Default GENERATOR is <class 'ednaml.generators.AlbertGenerator.AlbertGenerator'>\n",
      "20:35:15 Updating CRAWLER to NELACrawler\n",
      "20:35:15 Crawling /content/drive/MyDrive/Data\n",
      "Building Transforms\n",
      "Building Dataset\n",
      "100% 1/1 [00:01<00:00,  1.31s/it]\n",
      "Building Dataloader\n",
      "20:35:19 Generated training data generator with 5299 training data points\n",
      "20:35:19 Running classification model with classes: {'reliability': {'classes': 2}}\n",
      "Building Transforms\n",
      "Building Dataset\n",
      "100% 1/1 [00:00<00:00,  6.35it/s]\n",
      "Building Dataloader\n",
      "20:35:19 Generated test data/query generator\n",
      "20:35:19 Loaded ednaml_model_builder from ednaml.models to build model\n",
      "loading weights file pytorch_model.bin\n",
      "Errors \n",
      "\t {'missing_keys': [], 'unexpected_keys': [], 'error_msgs': []}\n",
      "20:35:19 Finished instantiating model with NELAModel architecture\n",
      "20:35:19 Adding plugins after constructing model\n",
      "20:35:19 No saved model weights provided.\n",
      "INPUT SIZE ====  (128, 512)\n",
      "/usr/local/lib/python3.9/dist-packages/torchinfo/torchinfo.py:477: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n",
      "/usr/local/lib/python3.9/dist-packages/torch/storage.py:665: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return super().__sizeof__() + self.nbytes()\n",
      "20:35:21 ========================================================================================================================================================================================================\n",
      "Layer (type:depth-idx)                                                      Input Shape               Output Shape              Param #                   Kernel Shape              Mult-Adds\n",
      "========================================================================================================================================================================================================\n",
      "NELAModel                                                                   [128, 512]                [128, 2]                  --                        --                        --\n",
      "├─AlbertModel: 1-1                                                          [128, 512]                [128, 512, 768]           --                        --                        --\n",
      "│    └─AlbertEmbeddings: 2-1                                                [128, 512]                [128, 512, 128]           --                        --                        --\n",
      "│    │    └─Embedding: 3-1                                                  [128, 512]                [128, 512, 128]           3,840,000                 --                        491,520,000\n",
      "│    │    └─Embedding: 3-2                                                  [128, 512]                [128, 512, 128]           65,536                    --                        8,388,608\n",
      "│    │    └─Embedding: 3-3                                                  [128, 512]                [128, 512, 128]           256                       --                        32,768\n",
      "│    │    └─LayerNorm: 3-4                                                  [128, 512, 128]           [128, 512, 128]           256                       --                        32,768\n",
      "│    │    └─Dropout: 3-5                                                    [128, 512, 128]           [128, 512, 128]           --                        --                        --\n",
      "│    └─AlbertEncoder: 2-2                                                   [128, 512, 128]           [128, 512, 768]           --                        --                        --\n",
      "│    │    └─Linear: 3-6                                                     [128, 512, 128]           [128, 512, 768]           99,072                    --                        12,681,216\n",
      "│    │    └─AlbertTransformer: 3-7                                          [128, 512, 768]           [128, 512, 768]           7,087,872                 --                        10,886,971,392\n",
      "│    └─AlbertPooler: 2-3                                                    [128, 512, 768]           [128, 768]                --                        --                        --\n",
      "│    │    └─Linear: 3-8                                                     [128, 768]                [128, 768]                590,592                   --                        75,595,776\n",
      "│    │    └─Tanh: 3-9                                                       [128, 768]                [128, 768]                --                        --                        --\n",
      "├─AlbertPooledOutput: 1-2                                                   [128, 512, 768]           [128, 768]                --                        --                        --\n",
      "├─Dropout: 1-3                                                              [128, 768]                [128, 768]                --                        --                        --\n",
      "├─Linear: 1-4                                                               [128, 768]                [128, 2]                  1,538                     --                        196,864\n",
      "========================================================================================================================================================================================================\n",
      "Total params: 11,685,122\n",
      "Trainable params: 11,685,122\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 11.48\n",
      "========================================================================================================================================================================================================\n",
      "Input size (MB): 0.52\n",
      "Forward/backward pass size (MB): 53822.10\n",
      "Params size (MB): 46.74\n",
      "Estimated Total Size (MB): 53869.36\n",
      "========================================================================================================================================================================================================\n",
      "20:35:21 Loaded ClassificationOptimizer from ednaml.optimizer to build Optimizer model\n",
      "20:35:21 Built optimizer\n",
      "20:35:21 Built scheduler\n",
      "20:35:21 Added SoftmaxLogitsLoss with lambda = 1.0 and loss arguments {}\n",
      "20:35:21 Built loss function\n",
      "20:35:21 Built loss optimizer\n",
      "20:35:21 Built loss scheduler\n",
      "20:35:21 Loaded BaseStorage from ednaml.storage to build Storage\n",
      "NOT saving metadata. saveMetadata() function not set up.\n",
      "20:35:21 1 GPUs available\n",
      "20:35:21 Starting training\n",
      "20:35:21 Logging to:\tnela-v5-albert-covid20-logger.log\n",
      "20:35:21 Models will be saved to local directory:\tnela-v5-albert-covid20\n",
      "20:35:21 Models will be backed up to drive directory:\t./drive/MyDrive/Projects/NELA/Models/nela-v5-albert-covid20\n",
      "20:35:21 Models will be saved with base name:\tnela-v5_epoch[].pth\n",
      "20:35:21 Optimizers will be saved with base name:\tnela-v5_epoch[]_optimizer.pth\n",
      "20:35:21 Schedulers will be saved with base name:\tnela-v5_epoch[]_scheduler.pth\n",
      "20:35:21 Performing initial evaluation...\n",
      "20:35:27 Obtained logits and labels, validation in progress\n",
      "20:35:27 \tAccuracy: 36.295%\n",
      "20:35:27 \tMicro F-score: 0.363\n",
      "20:35:27 \tWeighted F-score: 0.193\n",
      "20:35:27 Starting training from 0\n",
      "20:35:27 Parameter Group `opt-1`: Starting epoch 0 with 40 steps and learning rate 1.00000E-05\n",
      "20:35:54 ********** Completed epoch 0 **********\n",
      "20:35:54 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:35:54 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:35:55 Parameter Group `opt-1`: Starting epoch 1 with 40 steps and learning rate 1.00000E-05\n",
      "20:35:59 Evaluating model at test-frequency\n",
      "20:36:00 Obtained logits and labels, validation in progress\n",
      "20:36:00 \tAccuracy: 65.964%\n",
      "20:36:00 \tMicro F-score: 0.660\n",
      "20:36:00 \tWeighted F-score: 0.550\n",
      "20:36:00 Saving model at save-frequency, at epoch 0, step 0\n",
      "20:36:00 Saving model, optimizer, and scheduler.\n",
      "20:36:01 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:36:25 ********** Completed epoch 1 **********\n",
      "20:36:25 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:36:25 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:36:25 Parameter Group `opt-1`: Starting epoch 2 with 40 steps and learning rate 1.00000E-05\n",
      "20:36:28 Evaluating model at test-frequency\n",
      "20:36:29 Obtained logits and labels, validation in progress\n",
      "20:36:29 \tAccuracy: 73.795%\n",
      "20:36:29 \tMicro F-score: 0.738\n",
      "20:36:29 \tWeighted F-score: 0.701\n",
      "20:36:29 Saving model at save-frequency, at epoch 1, step 0\n",
      "20:36:29 Saving model, optimizer, and scheduler.\n",
      "20:36:30 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:36:57 ********** Completed epoch 2 **********\n",
      "20:36:57 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:36:57 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:36:57 Parameter Group `opt-1`: Starting epoch 3 with 40 steps and learning rate 5.00000E-06\n",
      "20:36:58 Evaluating model at test-frequency\n",
      "20:37:00 Obtained logits and labels, validation in progress\n",
      "20:37:00 \tAccuracy: 73.946%\n",
      "20:37:00 \tMicro F-score: 0.739\n",
      "20:37:00 \tWeighted F-score: 0.727\n",
      "20:37:00 Saving model at save-frequency, at epoch 2, step 0\n",
      "20:37:00 Saving model, optimizer, and scheduler.\n",
      "20:37:00 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:37:29 ********** Completed epoch 3 **********\n",
      "20:37:29 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:37:29 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:37:29 Parameter Group `opt-1`: Starting epoch 4 with 40 steps and learning rate 5.00000E-06\n",
      "20:37:35 Evaluating model at test-frequency\n",
      "20:37:36 Obtained logits and labels, validation in progress\n",
      "20:37:36 \tAccuracy: 78.614%\n",
      "20:37:36 \tMicro F-score: 0.786\n",
      "20:37:36 \tWeighted F-score: 0.776\n",
      "20:37:36 Saving model at save-frequency, at epoch 3, step 0\n",
      "20:37:36 Saving model, optimizer, and scheduler.\n",
      "20:37:37 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:38:01 ********** Completed epoch 4 **********\n",
      "20:38:01 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:38:01 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:38:01 Parameter Group `opt-1`: Starting epoch 5 with 40 steps and learning rate 5.00000E-06\n",
      "20:38:05 Evaluating model at test-frequency\n",
      "20:38:07 Obtained logits and labels, validation in progress\n",
      "20:38:07 \tAccuracy: 79.066%\n",
      "20:38:07 \tMicro F-score: 0.791\n",
      "20:38:07 \tWeighted F-score: 0.791\n",
      "20:38:07 Saving model at save-frequency, at epoch 4, step 0\n",
      "20:38:07 Saving model, optimizer, and scheduler.\n",
      "20:38:08 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:38:32 ********** Completed epoch 5 **********\n",
      "20:38:32 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:38:32 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:38:33 Parameter Group `opt-1`: Starting epoch 6 with 40 steps and learning rate 2.50000E-06\n",
      "20:38:36 Evaluating model at test-frequency\n",
      "20:38:37 Obtained logits and labels, validation in progress\n",
      "20:38:37 \tAccuracy: 79.970%\n",
      "20:38:37 \tMicro F-score: 0.800\n",
      "20:38:37 \tWeighted F-score: 0.800\n",
      "20:38:37 Saving model at save-frequency, at epoch 5, step 0\n",
      "20:38:37 Saving model, optimizer, and scheduler.\n",
      "20:38:38 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:39:05 ********** Completed epoch 6 **********\n",
      "20:39:05 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:39:05 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:39:05 Parameter Group `opt-1`: Starting epoch 7 with 40 steps and learning rate 2.50000E-06\n",
      "20:39:06 Evaluating model at test-frequency\n",
      "20:39:08 Obtained logits and labels, validation in progress\n",
      "20:39:08 \tAccuracy: 80.120%\n",
      "20:39:08 \tMicro F-score: 0.801\n",
      "20:39:08 \tWeighted F-score: 0.800\n",
      "20:39:08 Saving model at save-frequency, at epoch 6, step 0\n",
      "20:39:08 Saving model, optimizer, and scheduler.\n",
      "20:39:09 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:39:37 ********** Completed epoch 7 **********\n",
      "20:39:37 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:39:37 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:39:37 Parameter Group `opt-1`: Starting epoch 8 with 40 steps and learning rate 2.50000E-06\n",
      "20:39:43 Evaluating model at test-frequency\n",
      "20:39:44 Obtained logits and labels, validation in progress\n",
      "20:39:44 \tAccuracy: 79.518%\n",
      "20:39:44 \tMicro F-score: 0.795\n",
      "20:39:44 \tWeighted F-score: 0.794\n",
      "20:39:44 Saving model at save-frequency, at epoch 7, step 0\n",
      "20:39:44 Saving model, optimizer, and scheduler.\n",
      "20:39:45 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:40:09 ********** Completed epoch 8 **********\n",
      "20:40:09 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:40:09 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:40:09 Parameter Group `opt-1`: Starting epoch 9 with 40 steps and learning rate 1.25000E-06\n",
      "20:40:13 Evaluating model at test-frequency\n",
      "20:40:15 Obtained logits and labels, validation in progress\n",
      "20:40:15 \tAccuracy: 79.066%\n",
      "20:40:15 \tMicro F-score: 0.791\n",
      "20:40:15 \tWeighted F-score: 0.790\n",
      "20:40:15 Saving model at save-frequency, at epoch 8, step 0\n",
      "20:40:15 Saving model, optimizer, and scheduler.\n",
      "20:40:16 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:40:41 ********** Completed epoch 9 **********\n",
      "20:40:41 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:40:41 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:40:41 Parameter Group `opt-1`: Starting epoch 10 with 40 steps and learning rate 1.25000E-06\n",
      "20:40:44 Evaluating model at test-frequency\n",
      "20:40:46 Obtained logits and labels, validation in progress\n",
      "20:40:46 \tAccuracy: 79.819%\n",
      "20:40:46 \tMicro F-score: 0.798\n",
      "20:40:46 \tWeighted F-score: 0.797\n",
      "20:40:46 Saving model at save-frequency, at epoch 9, step 0\n",
      "20:40:46 Saving model, optimizer, and scheduler.\n",
      "20:40:46 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:41:13 ********** Completed epoch 10 **********\n",
      "20:41:13 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:41:13 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:41:13 Parameter Group `opt-1`: Starting epoch 11 with 40 steps and learning rate 1.25000E-06\n",
      "20:41:15 Evaluating model at test-frequency\n",
      "20:41:16 Obtained logits and labels, validation in progress\n",
      "20:41:16 \tAccuracy: 79.518%\n",
      "20:41:16 \tMicro F-score: 0.795\n",
      "20:41:16 \tWeighted F-score: 0.794\n",
      "20:41:16 Saving model at save-frequency, at epoch 10, step 0\n",
      "20:41:16 Saving model, optimizer, and scheduler.\n",
      "20:41:17 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:41:45 ********** Completed epoch 11 **********\n",
      "20:41:45 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:41:45 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:41:45 Parameter Group `opt-1`: Starting epoch 12 with 40 steps and learning rate 6.25000E-07\n",
      "20:41:51 Evaluating model at test-frequency\n",
      "20:41:52 Obtained logits and labels, validation in progress\n",
      "20:41:52 \tAccuracy: 80.422%\n",
      "20:41:52 \tMicro F-score: 0.804\n",
      "20:41:52 \tWeighted F-score: 0.803\n",
      "20:41:52 Saving model at save-frequency, at epoch 11, step 0\n",
      "20:41:52 Saving model, optimizer, and scheduler.\n",
      "20:41:53 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:42:17 ********** Completed epoch 12 **********\n",
      "20:42:17 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:42:17 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:42:17 Parameter Group `opt-1`: Starting epoch 13 with 40 steps and learning rate 6.25000E-07\n",
      "20:42:21 Evaluating model at test-frequency\n",
      "20:42:23 Obtained logits and labels, validation in progress\n",
      "20:42:23 \tAccuracy: 79.970%\n",
      "20:42:23 \tMicro F-score: 0.800\n",
      "20:42:23 \tWeighted F-score: 0.798\n",
      "20:42:23 Saving model at save-frequency, at epoch 12, step 0\n",
      "20:42:23 Saving model, optimizer, and scheduler.\n",
      "20:42:23 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:42:48 ********** Completed epoch 13 **********\n",
      "20:42:48 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:42:48 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:42:48 Parameter Group `opt-1`: Starting epoch 14 with 40 steps and learning rate 6.25000E-07\n",
      "20:42:51 Evaluating model at test-frequency\n",
      "20:42:53 Obtained logits and labels, validation in progress\n",
      "20:42:53 \tAccuracy: 80.873%\n",
      "20:42:53 \tMicro F-score: 0.809\n",
      "20:42:53 \tWeighted F-score: 0.808\n",
      "20:42:53 Saving model at save-frequency, at epoch 13, step 0\n",
      "20:42:53 Saving model, optimizer, and scheduler.\n",
      "20:42:54 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:43:20 ********** Completed epoch 14 **********\n",
      "20:43:20 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:43:20 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:43:20 Parameter Group `opt-1`: Starting epoch 15 with 40 steps and learning rate 3.12500E-07\n",
      "20:43:22 Evaluating model at test-frequency\n",
      "20:43:23 Obtained logits and labels, validation in progress\n",
      "20:43:23 \tAccuracy: 81.175%\n",
      "20:43:23 \tMicro F-score: 0.812\n",
      "20:43:23 \tWeighted F-score: 0.811\n",
      "20:43:23 Saving model at save-frequency, at epoch 14, step 0\n",
      "20:43:23 Saving model, optimizer, and scheduler.\n",
      "20:43:24 Performing drive backup of model, optimizer, and scheduler.\n",
      "20:43:52 ********** Completed epoch 15 **********\n",
      "20:43:52 Model evaluation triggered, but gradients still need accumulation. Will evaluate after accumulation.\n",
      "20:43:52 Model save triggered, but gradients still need accumulation. Will save after accumulation.\n",
      "20:43:52 Final: Evaluating model at test-frequency\n",
      "20:43:54 Obtained logits and labels, validation in progress\n",
      "20:43:54 \tAccuracy: 81.024%\n",
      "20:43:54 \tMicro F-score: 0.810\n",
      "20:43:54 \tWeighted F-score: 0.809\n",
      "20:43:54 Final: Saving model at save-frequency\n",
      "20:43:54 Saving model, optimizer, and scheduler.\n",
      "20:43:55 Performing drive backup of model, optimizer, and scheduler.\n"
     ]
    }
   ],
   "source": [
    "!python /content/EdnaML/profiles/NELA/nela.py /content/EdnaML/profiles/NELA/nela-covid-v0.yml test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I45khl9Bum_Y"
   },
   "source": [
    "# 5. Generate Labels from Experts\n",
    "\n",
    "Here, we will label FNC-Extended for a month with models from ENFD, Fakeddit, and NELA's Bert-variant models. For now, we will use the Albert-Base-v2 models only.\n",
    "\n",
    "The labels are generated with weak supervision using a combination of off-the-shelf expert models, with labels integrated with Snorkel, WeaSEL, or MiDAS, or a combination of the above.\n",
    "\n",
    "For each classifier, we will generate a text file with labels for each entry. Since there is no data shuffling, labels across text files will sync up. We will then upload these saved files to our Drive location for ease of access and future integration.\n",
    "\n",
    "We need the following outputs in each text file:\n",
    "  - **Predicted label.** 0 for True news, 1 for Fake news.\n",
    "  - **Distance-to-proxy (l2)**. Raw distance in embedding space to the nearest proxy.\n",
    "  - **Distance-to-proxy (cos)**. Cosine distance\n",
    "  - **High density set**. 0 or 1. Whether sample is in the high density set.\n",
    "  - **High density label**. The ground truth label of the corresponding high-density set cluster. This is the same as the proxy label, or nearest proxy label.\n",
    "  - **L-Score**. Smoothness score for the input using perturbations. Probably take the longest time.\n",
    "  - **L-Threshold**. The threshold for the nearest proxy / high density set.\n",
    "  - **Logit-confidence**. The raw logit probability of the predicted class.\n",
    "  - **Logit-average**. The average logit probability of the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nm5oOtUuXv1"
   },
   "outputs": [],
   "source": [
    "! rm -rf /content/test-datashard-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Iav_55EjkC4"
   },
   "outputs": [],
   "source": [
    "# See FNC Experts (And Masking!) notebook\n",
    "tweet_file = \"tweets-2020-01-22\"\n",
    "\n",
    "# efnd | nela | fakeddit\n",
    "dataset = \"fakeddit\"\n",
    "\n",
    "# (ONLY FOR efnd; OTHERS YOU CAN IGNORE)\n",
    "# cmu_miscov19 | kagglefn_short | kagglefn_long | cov19_fn_title | cov19_fn_text | coaid_news | cov_rumor | covid_fn | covid_cq\n",
    "subdataset = \"nela\"\n",
    "\n",
    "# nomask | rtm | rwm | ktm_tfidf | kwm_tfidf | ktm_att | kwm_att | ktrtm_tfidf | kwrwm_tfidf | ktrtm_att | kwrwm_att\n",
    "masking = \"nomask\"\n",
    "\n",
    "# albert-base-v2\n",
    "model = \"albert-base-v2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0rKQQ1_5AHa"
   },
   "source": [
    "## Applying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KfNxLlMNYNFU"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Select the correct model-file!\n",
    "model_variant = \"./EdnaML/profiles/FNC/experts/configs/model-bertvariant.yml\"\n",
    "\n",
    "# plugin deploy file and proxies\n",
    "plugin_deploy_generation_file = \"./EdnaML/profiles/FNC/experts/plugin_generation.py\"\n",
    "plugin_proxies = {\"efnd-cmu_miscov19\": 20, \"efnd-kagglefn_short\": 40, \"efnd-kagglefn_long\": 20,\n",
    "                  \"efnd-cov19_fn_title\": 30, \"efnd-cov19_fn_text\": 35, \"efnd-coaid_news\": 50,\n",
    "                  \"efnd-cov_rumor\": 30, \"efnd-covid_fn\": 30, \"efnd-covid_cq\": 50,\n",
    "                  \"nela\": 40, \"fakeddit\": 30}\n",
    "if dataset == \"efnd\":\n",
    "  proxy = plugin_proxies[dataset + \"-\" + subdataset]\n",
    "else:\n",
    "  proxy = plugin_proxies[dataset]\n",
    "\n",
    "if dataset == \"efnd\":\n",
    "  #----------------------------- EFND ------------------------------------\n",
    "  dataset_args = {\n",
    "      \"data_folder\" : \"Data\",\n",
    "      \"include\": [subdataset]\n",
    "  }\n",
    "  model_qualifier = subdataset\n",
    "elif dataset == \"nela\":\n",
    "  #----------------------------- NELA ------------------------------------\n",
    "  dataset_args = {\n",
    "      \"data_folder\" : \"Data\",\n",
    "      \"sub_folder\" : \"nela-covid-2020\"\n",
    "  }\n",
    "  model_qualifier = \"nela_covid_2020\"\n",
    "elif dataset == \"fakeddit\":\n",
    "  #----------------------------- FAKEDDIT ------------------------------------\n",
    "  dataset_args = {\n",
    "      \"data_folder\" : \"Data\"\n",
    "  }\n",
    "  model_qualifier = \"fakeddit\"\n",
    "else:\n",
    "  raise NotImplementedError()\n",
    "\n",
    "# nomask | rtm | rwm | ktm_tfidf | kwm_tfidf | ktm_att | kwm_att | ktrtm_tfidf | kwrwm_tfidf | ktrtm_att | kwrwm_att\n",
    "mask_overall = True;tm = False;wm = False;ktm=False;kwm=False;\n",
    "if masking == \"nomask\":\n",
    "  mask_overall = False\n",
    "if masking == \"rtm\" or masking == \"ktrtm_tfidf\" or masking == \"ktrtm_att\":\n",
    "  tm = True\n",
    "if masking == \"rwm\" or masking == \"kwrwm_tfidf\" or masking == \"kwrwm_att\":\n",
    "  wm = True\n",
    "if masking == \"ktm_tfidf\" or masking == \"ktm_att\" or masking == \"ktrtm_att\":\n",
    "  ktm = True\n",
    "if masking == \"kwm_tfidf\" or masking == \"kwm_att\" or masking == \"kwrwm_att\":\n",
    "  kwm = True\n",
    "\n",
    "# Other options\n",
    "model_core_name = \"-\".join([\"fnc\",\"expert\",dataset, masking])\n",
    "model_backbone = model\n",
    "model_base = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3K40ykXsESB3"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2TvORAG_25Y"
   },
   "outputs": [],
   "source": [
    "import ednaml, torch\n",
    "from ednaml.core import EdnaDeploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLOF-jQ-KIbw"
   },
   "outputs": [],
   "source": [
    "from ednaml.deploy.HFDeploy import HFDeploy\n",
    "import os\n",
    "\n",
    "class LabelingDeployment(HFDeploy):\n",
    "  def output_setup(self, **kwargs):\n",
    "    self.ofile = kwargs.get(\"label_file_name\")\n",
    "    if self.ofile == \"None\":\n",
    "      raise ValueError(\"No filename provided\")\n",
    "    self.oobj = open(self.ofile, \"w\")\n",
    "    self.oobj.write(\",\".join([\n",
    "      \"predicted_label\",\n",
    "      \"l2_dist\",\n",
    "      \"l2_hdthreshold\",\n",
    "      \"l2_proxylabels\",\n",
    "      \"cos_dist\",\n",
    "      \"cos_hdthreshold\",\n",
    "      \"cos_proxylabels\",\n",
    "      \"l_score\",\n",
    "      \"smooth_l_score\",\n",
    "      \"l_threshold\",\n",
    "      \"smooth_l_threshold\",\n",
    "      \"l_proxylabel\",\n",
    "      \"logit_raw\",\n",
    "      \"logit_threshold\"\n",
    "      ])+\"\\n\")\n",
    "\n",
    "  def output_step(self, logits, features, secondary):\n",
    "    predicted_label = torch.argmax(torch.nn.functional.softmax(logits.cpu(), dim=1), dim=1).tolist()\n",
    "    print(secondary[2])\n",
    "    l2_dist = secondary[2][\"FastKMP-l2\"][\"distance\"].to(torch.float32).tolist()\n",
    "    l2_hdthreshold = secondary[2][\"FastKMP-l2\"][\"threshold\"].to(torch.float32).tolist()\n",
    "    l2_proxylabels = secondary[2][\"FastKMP-l2\"][\"proxy_labels\"].to(torch.float32).tolist()\n",
    "\n",
    "    cos_dist = secondary[2][\"FastKMP-cos\"][\"distance\"].to(torch.float32).tolist()\n",
    "    cos_hdthreshold = secondary[2][\"FastKMP-cos\"][\"threshold\"].to(torch.float32).tolist()\n",
    "    cos_proxylabels = secondary[2][\"FastKMP-cos\"][\"proxy_labels\"].to(torch.float32).tolist()\n",
    "\n",
    "    l_score = secondary[2][\"FRL-midas\"][\"l_score\"]\n",
    "    smooth_l_score = secondary[2][\"FRL-midas\"][\"smooth_l_score\"]\n",
    "    l_threshold = secondary[2][\"FRL-midas\"][\"l_threshold\"]\n",
    "    smooth_l_threshold = secondary[2][\"FRL-midas\"][\"smooth_l_threshold\"]\n",
    "    l_proxylabel = secondary[2][\"FRL-midas\"][\"proxy_label\"].to(torch.float32).tolist()\n",
    "\n",
    "    logit_raw = secondary[2][\"logit-confidence\"][\"logit\"].to(torch.float32).tolist()\n",
    "    logit_threshold = secondary[2][\"logit-confidence\"][\"logit_threshold\"].to(torch.float32).tolist()\n",
    "\n",
    "    output_list = [\",\".join(map(str,item)) for item in zip(\n",
    "      predicted_label,\n",
    "      l2_dist,\n",
    "      l2_hdthreshold,\n",
    "      l2_proxylabels,\n",
    "      cos_dist,\n",
    "      cos_hdthreshold,\n",
    "      cos_proxylabels,\n",
    "      l_score,\n",
    "      smooth_l_score,\n",
    "      l_threshold,\n",
    "      smooth_l_threshold,\n",
    "      l_proxylabel,\n",
    "      logit_raw,\n",
    "      logit_threshold\n",
    "      )]\n",
    "    self.oobj.write(\"\\n\".join(output_list)+\"\\n\")\n",
    "  def end_of_deployment(self):\n",
    "      self.oobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y4cCp18M_22i",
    "outputId": "a02bb139-d3c8-4199-9817-4bdd3a91a10d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:51:31 Adding a crawler, from /content/EdnaML/profiles/FNC/fnc-extended-labeling-crawler.py, with inferred name FNCCrawler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Injected key-value pair:  SAVE.MODEL_CORE_NAME, fnc-expert-fakeddit-nomask\n",
      "Injected key-value pair:  SAVE.MODEL_BACKBONE, albert-base-v2\n",
      "Injected key-value pair:  SAVE.MODEL_QUALIFIER, fakeddit\n",
      "Injected key-value pair:  SAVE.DRIVE_BACKUP, True\n",
      "Injected key-value pair:  SAVE.LOG_BACKUP, False\n",
      "Injected key-value pair:  MODEL.MODEL_BASE, albert-base-v2\n",
      "Injected key-value pair:  SAVE.SAVE_FREQUENCY, 5\n",
      "Injected key-value pair:  DEPLOYMENT.EPOCHS, 1\n",
      "Registering a crawler: <class './EdnaML/profiles/FNC/fnc-extended-labeling-crawler.py.FNCCrawler'>, from file: /content/EdnaML/profiles/FNC/fnc-extended-labeling-crawler.py\n"
     ]
    }
   ],
   "source": [
    "ed = EdnaDeploy(config=[\"./EdnaML/profiles/FNC/labeling/config_base.yml\",  # logging, deployment, crawler\n",
    "                          model_variant,\n",
    "                        \"./EdnaML/profiles/FNC/experts/configs/plugin_base.yml\"],\n",
    "                config_inject = [\n",
    "                    (\"SAVE.MODEL_CORE_NAME\", model_core_name),\n",
    "                    (\"SAVE.MODEL_BACKBONE\", model_backbone),\n",
    "                    (\"SAVE.MODEL_QUALIFIER\", model_qualifier),\n",
    "                    (\"SAVE.DRIVE_BACKUP\", True),\n",
    "                    (\"SAVE.LOG_BACKUP\", False),\n",
    "                    (\"MODEL.MODEL_BASE\", model_backbone),\n",
    "                    (\"SAVE.SAVE_FREQUENCY\", 5), # To ensure nothing actually gets saved, since we only run for 1 epoch\n",
    "                    (\"DEPLOYMENT.EPOCHS\", 1)\n",
    "                ],\n",
    "                weights=\"/content/experiment_epoch1_step16825_model.pth\"\n",
    "                )\n",
    "\n",
    "ed.cfg.DEPLOYMENT.OUTPUT_ARGS[\"label_file_name\"] = tweet_file + \"-\" + ed.saveMetadata.MODEL_SAVE_FOLDER+\".csv\"\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.CRAWLER_ARGS[\"azfile\"] = \"%s-extended.json.gz\"%tweet_file\n",
    "# No masking for everything, so we will not edit it here.\n",
    "\n",
    "\n",
    "ed.add(\"./EdnaML/profiles/FNC/fnc-extended-labeling-crawler.py\")\n",
    "ed.addDeploymentClass(LabelingDeployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1437dcb8e72e47bcaee86f449d9ea988",
      "26d21e135f0a45f4a3b3815640820127",
      "68c32fa3f36a468594630561113fc413",
      "48c8eda152c24ec8a30e76d04fcba80a",
      "76658d325ca94c609bd7b0b12f5e712a",
      "29e67a65e4644c65a1139315d3e8aa88",
      "d02d5ed1cfa54810a65f2760931d658d",
      "43031f69a5f24a6e887b0a88453607fd",
      "ec0f092cce1d4aa0bece4ed6ae5ce6a6",
      "5b346f92c5474fb89628e8945d6f50db",
      "44c40375cf144643acfed61faba76c85",
      "5eeb8f4c346a4faaa7bcb38e6aea46d7",
      "234c95fe23914f2892520cf915f93b69",
      "208e6906fc8441939c6bf772e535ae51",
      "fe60701859c4438295b78c3cfa5a2959",
      "e5ce333f6962496b82e1ec28f8273bb3",
      "2181cb6323864c70835626fbebbadb78",
      "e091a3cc32af43cfb91ff0045ef1e135",
      "4ee3ab4c1db1443abc2f0fbf5e6f3eea",
      "5f7356c6607b4d179842af7f76c5f718",
      "2aef35ff068549c7aad0d8cc2dffd5cc",
      "a3911953fe9a48edb216286426690a92",
      "0126ac625ee3483abd82020e6fb7e5e5",
      "9e84e6f2b9604d85b8b9e9e20ed27342",
      "506726ca155a4c53aaebb3beaa799f2b",
      "c6b19b4a4e64496c837bda7cc2bddd9e",
      "e5a7aa355be9465bb255259c0b20a290",
      "f983a4dc6b734f6bab93d45465a4d532",
      "56cc7969932a41fda43c0ebadf3d461d",
      "22879b070c9c44c4a21c81adf2e21b16",
      "617df262a1974dcfaec3bf2087f983b8",
      "cd3acc7636594daaa8958b3ed70f06e2",
      "213669cd5e044ceba85f9fdc6288f508",
      "71f734ed764e4f8080851fcbb44d21ee",
      "c0afdcb7490e4078b1121147b4253375",
      "f732452fc9914305b101d8952fcdeb54",
      "0832bd86bbe34fb6be862ee277bc35d9",
      "2ba9f72aa1384cf3ab53337075f37595",
      "791216707e14473ea42aaa34f794c255",
      "b563ebb5f5834c0ab534e33c0855d74f",
      "919131d306424b18b71fd4cc0f32c4f7",
      "39fe5260da0d4eed961ef568439129a3",
      "5123670e39dc40b3a32a2ee8bac58c05",
      "6dbb5a55fd364835b8f6c9a9ef5a99d4"
     ]
    },
    "id": "k6nKa_ixKEOT",
    "outputId": "ea35fd4b-9a2d-40c1-d384-e6cae75c7920"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:51:31 ****************************************\n",
      "01:51:31 \n",
      "01:51:31 \n",
      "01:51:31 Using the following configuration:\n",
      "01:51:31 DEPLOYMENT:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS:\n",
      "      azcontainer: edna-covid-extended\n",
      "      azfile: tweets-2020-01-22-extended.json.gz\n",
      "      azstorage: ednadatasets\n",
      "    DATAREADER: HFReader\n",
      "    DATASET_ARGS:\n",
      "      annotation_idxs:\n",
      "      - 1\n",
      "      - 2\n",
      "      classificationclass:\n",
      "      - fnews\n",
      "      data_shuffle: false\n",
      "      keyword_mask: true\n",
      "      keywords: []\n",
      "      label_idxs:\n",
      "      - 3\n",
      "      masking: false\n",
      "      maxlen: 512\n",
      "      mlm_probability: 0.15\n",
      "      shard_replace: false\n",
      "      shardcache: true\n",
      "      shardname: fnc-extended-shard\n",
      "      shardpath: datashard-artifacts\n",
      "      shardsize: 20000\n",
      "      shuffle: false\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  DEPLOY: HFDeploy\n",
      "  DEPLOYMENT_ARGS: {}\n",
      "  EPOCHS: 1\n",
      "  OUTPUT_ARGS:\n",
      "    label_file_name: tweets-2020-01-22-fnc-expert-fakeddit-nomask-v2-albert-base-v2-fakeddit.csv\n",
      "  PLUGIN:\n",
      "    HOOKS: activated\n",
      "    RESET: false\n",
      "EXECUTION:\n",
      "  DATAREADER:\n",
      "    CRAWLER_ARGS: {}\n",
      "    DATAREADER: DataReader\n",
      "    DATASET_ARGS: {}\n",
      "    GENERATOR: null\n",
      "    GENERATOR_ARGS:\n",
      "      from_pretrained: albert-base-v2\n",
      "      tokenizer: HFAutoTokenizer\n",
      "  EPOCHS: 10\n",
      "  FP16: false\n",
      "  MODEL_SERVING: false\n",
      "  OPTIMIZER_BUILDER: ClassificationOptimizer\n",
      "  PLUGIN:\n",
      "    HOOKS: always\n",
      "    RESET: false\n",
      "  SKIPEVAL: false\n",
      "  TEST_FREQUENCY: 1\n",
      "  TRAINER: BaseTrainer\n",
      "  TRAINER_ARGS:\n",
      "    accumulation_steps: 1\n",
      "LOGGING:\n",
      "  INPUT_SIZE:\n",
      "  - 16\n",
      "  - 512\n",
      "  STEP_VERBOSE: 100\n",
      "LOSS: []\n",
      "LOSS_OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "LOSS_SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "MODEL:\n",
      "  BUILDER: ednaml_model_builder\n",
      "  MODEL_ARCH: HFAutoModel\n",
      "  MODEL_BASE: albert-base-v2\n",
      "  MODEL_KWARGS:\n",
      "    auto_class: AutoModelForSequenceClassification\n",
      "    hidden_act: gelu\n",
      "    pooling: pooled\n",
      "  MODEL_NORMALIZATION: bn\n",
      "  PARAMETER_GROUPS:\n",
      "  - opt-1\n",
      "MODEL_PLUGIN:\n",
      "  FRL-midas:\n",
      "    PLUGIN: FastRandomizedLipschitz\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.6\n",
      "      batch_size: 256\n",
      "      classifier_access: encoder.classifier\n",
      "      dimensions: 768\n",
      "      dist: euclidean\n",
      "      iterations: 30\n",
      "      proxies: 15\n",
      "      proxy_epochs: 1\n",
      "    PLUGIN_NAME: FRL-midas\n",
      "  FastKMP-cos:\n",
      "    PLUGIN: FastKMeansProxy\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.6\n",
      "      batch_size: 256\n",
      "      classifier_access: encoder.classifier\n",
      "      dimensions: 768\n",
      "      dist: cosine\n",
      "      iterations: 30\n",
      "      proxies: 20\n",
      "    PLUGIN_NAME: FastKMP-cos\n",
      "  FastKMP-l2:\n",
      "    PLUGIN: FastKMeansProxy\n",
      "    PLUGIN_KWARGS:\n",
      "      alpha: 0.6\n",
      "      batch_size: 256\n",
      "      classifier_access: encoder.classifier\n",
      "      dimensions: 768\n",
      "      dist: euclidean\n",
      "      iterations: 30\n",
      "      proxies: 20\n",
      "    PLUGIN_NAME: FastKMP-l2\n",
      "  logit-confidence:\n",
      "    PLUGIN: LogitConfidence\n",
      "    PLUGIN_KWARGS:\n",
      "      num_classes: 2\n",
      "    PLUGIN_NAME: logit-confidence\n",
      "OPTIMIZER:\n",
      "- BASE_LR: 0.001\n",
      "  LR_BIAS_FACTOR: 1.0\n",
      "  OPTIMIZER: Adam\n",
      "  OPTIMIZER_KWARGS: {}\n",
      "  OPTIMIZER_NAME: opt-1\n",
      "  WEIGHT_BIAS_FACTOR: 0.0005\n",
      "  WEIGHT_DECAY: 0.0005\n",
      "SAVE:\n",
      "  CHECKPOINT_DIRECTORY: ./drive/MyDrive/Projects/FNC/Models/\n",
      "  DRIVE_BACKUP: true\n",
      "  LOG_BACKUP: false\n",
      "  MODEL_BACKBONE: albert-base-v2\n",
      "  MODEL_CORE_NAME: fnc-expert-fakeddit-nomask\n",
      "  MODEL_QUALIFIER: fakeddit\n",
      "  MODEL_VERSION: 2\n",
      "  SAVE_FREQUENCY: 5\n",
      "  STEP_SAVE_FREQUENCY: 0\n",
      "SCHEDULER:\n",
      "- LR_KWARGS:\n",
      "    step_size: 20\n",
      "  LR_SCHEDULER: StepLR\n",
      "  SCHEDULER_NAME: opt-1\n",
      "STORAGE:\n",
      "  STORAGE_ARGS: {}\n",
      "  TYPE: BaseStorage\n",
      "  URL: ./\n",
      "TEST_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 1\n",
      "TRAIN_TRANSFORMATION:\n",
      "  ARGS: {}\n",
      "  BATCH_SIZE: 16\n",
      "  WORKERS: 1\n",
      "extensions:\n",
      "- EXECUTION\n",
      "- SAVE\n",
      "- STORAGE\n",
      "- TRANSFORMATION\n",
      "- MODEL\n",
      "- LOSS\n",
      "- OPTIMIZER\n",
      "- SCHEDULER\n",
      "- LOSS_OPTIMIZER\n",
      "- LOSS_SCHEDULER\n",
      "- LOGGING\n",
      "- DEPLOYMENT\n",
      "- MODEL_PLUGIN\n",
      "\n",
      "01:51:31 \n",
      "01:51:31 \n",
      "01:51:31 ****************************************\n",
      "01:51:31 Not downloading weights. Weights path already provided.\n",
      "01:51:33 No previous stop detected. Will start from epoch 0\n",
      "01:51:33 Reading data with DataReader HFReader\n",
      "01:51:33 Default CRAWLER is <class 'ednaml.crawlers.Crawler'>\n",
      "01:51:33 Default DATASET is <class 'ednaml.generators.HFGenerator.HFDataset'>\n",
      "01:51:33 Default GENERATOR is <class 'ednaml.generators.HFGenerator.HFGenerator'>\n",
      "01:51:33 Updating CRAWLER to FNCCrawler\n",
      "01:51:33 Crawling https://ednadatasets.blob.core.windows.net/edna-covid-extended/tweets-2020-01-22-extended.json.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3992159/3992159 bytes [████████████████████████████████████████████████████████████████████████████████████████████████████]\n",
      "Download of tweets-2020-01-22-extended.json.gz to https://ednadatasets.blob.core.windows.net/edna-covid-extended/tweets-2020-01-22-extended.json.gz completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:51:37 Generating dataloader `HFGenerator` with `test` mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Transforms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1437dcb8e72e47bcaee86f449d9ea988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eeb8f4c346a4faaa7bcb38e6aea46d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0126ac625ee3483abd82020e6fb7e5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:51:41 [Mode `test`] Will look in path [test-datashard-artifacts] for shards `fnc-extended-shard-[e].pt`\n",
      "01:51:41 Shards do not exist and will be created.\n",
      "01:51:41 Creating shardpath test-datashard-artifacts\n",
      "01:51:41 Generating shards\n",
      "01:51:41 Generating shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.48s/it]\n",
      "01:51:59 Obtained 1 shards\n",
      "01:52:00 Generated test data/query generator\n",
      "01:52:00 Loaded ednaml_model_builder from ednaml.models to build model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dataloader\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f734ed764e4f8080851fcbb44d21ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "01:52:01 Finished instantiating model with HFAutoModel architecture\n",
      "01:52:01 Adding plugins after constructing model\n",
      "01:52:01 Added plugin FastKMP-l2\n",
      "01:52:01 Added plugin FastKMP-cos\n",
      "01:52:01 Added plugin FRL-midas\n",
      "01:52:01 Added plugin logit-confidence\n",
      "01:52:01 Loading weights from /content/experiment_epoch1_step16825_model.pth\n",
      "01:52:06 Model Summary retured the following error:\n",
      "01:52:06 Traceback (most recent call last):\n",
      "  File \"/content/EdnaML/src/ednaml/core/EdnaML.py\", line 888, in getModelSummary\n",
      "    self.cfg.TRAIN_TRANSFORMATION.INPUT_SIZE,\n",
      "AttributeError: 'TransformationConfig' object has no attribute 'INPUT_SIZE'\n",
      "\n",
      "01:52:06 1 GPUs available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT saving metadata. saveMetadata() function not set up.\n"
     ]
    }
   ],
   "source": [
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cZhe3AohKFJG",
    "outputId": "1bf43229-ac2c-46f0-eeee-cd605c2f113f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:21:02 Skipping model building because model is already built. To force, set the `model_build` flag to True in `ed.deploy`\n",
      "02:21:02 Setting up plugin hooks. Plugins will fire during:  activated\n",
      "02:21:02 Executing deployment for  1 epochs\n",
      "02:21:02 Starting epoch 0\n",
      "                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7e5cc19c5c24>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/EdnaML/src/ednaml/core/EdnaDeploy.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_stop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuildDeployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/EdnaML/src/ednaml/deploy/BaseDeploy.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, continue_epoch, continue_step, inference, ignore_plugins, execute, model_build)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting epoch %i\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_epoch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_epoch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/EdnaML/src/ednaml/deploy/BaseDeploy.py\u001b[0m in \u001b[0;36mdata_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mfeature_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecondary_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Log Metrics here and inside the model TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-961d86491efa>\u001b[0m in \u001b[0;36moutput_step\u001b[0;34m(self, logits, features, secondary)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecondary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0ml2_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecondary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FastKMP-l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0ml2_hdthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecondary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FastKMP-l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"threshold\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0ml2_proxylabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msecondary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FastKMP-l2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"proxy_labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FastKMP-l2'"
     ]
    }
   ],
   "source": [
    "ed.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-FHK2N8ebDm"
   },
   "outputs": [],
   "source": [
    "ed.model.plugins[\"FastKMP-l2\"].proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU0F_yBBffb6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"tweets-2020-01-22-fnc-expert-efnd-nomask-v1-albert-base-v2-kagglefn_short.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7zQy8x4fkbK"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xm3Kuc-NDKa"
   },
   "source": [
    "## Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZR5rjAnK_fx"
   },
   "source": [
    "# 6. Generate FNC-AlBERT\n",
    "\n",
    "Now, we generate an LLM specific for a window. We have several choices for windows, controlled by the first few cells:\n",
    "\n",
    "1. Daily window: Given a specific date, we will use the FNC-extended dataset for that day\n",
    "2. Monthly window: We aggregate all daily window FNC-extended datasets\n",
    "3. Sampled monthy/date range: Given a range of dates, we first aggregate the daily FNC-extended. Then, we sample from this aggregate ~100M data points.\n",
    "\n",
    "The LLM naming convention is: `FNC-AlBERT-<Month>-<Date>-<Year>-<Sampled>`. Here, `<Month>` is the named month (e.g. January, February); `<Date>` is only present for daily window; `<Year>` is the, well, year for the source data, and `<Sampled>` is only present if the source data is a sampled set. If it is a sampled set, then `<Sample>` is one of `MonthSample`, `Week<#>Sample`, `DaySample`. (`Week<#>Sample` is if the range is one week. We'll record the week number of the date range here.) Other sample ranges are not covered for conciseness.\n",
    "\n",
    "Our LLM Generation step, given a dataset, is as follows:\n",
    "\n",
    "1. Preprocess the data samples as: extract raw text, lowercase, discard retweet, word tokenize, record first 5 words in dict to discard duplicates; tokenize usernames (begins with @) with `[user]`, tokenize urls (begins with http) with [url], convert emojis to `:emojitext:` using emoji library; rejoin the word tokenized array to create the processed text. We write each text item to a like separated file.\n",
    "\n",
    "2. Shuffle the file. Then generate a pretraining file. Each document is line-separated. We don't care about NSP or SOP.\n",
    "\n",
    "3. Use the HFPretrainingGenerator to shard the data. Each sample has sentence. During data loading, random trigrams are masked (simpler than word masking). NSP unneeded, so only use MLM Head!!\n",
    "\n",
    "4. Use HFPretrainer to perform pretraining of AlBERTForPretraining. Generate a batch, and ignore NSP loss where not available.\n",
    "\n",
    "5. Train, and save every 30k epochs. Given batch size of 32 (tweet length...), we need to train for 3.2M steps!!! Note: we will use a aggregator of 32 as well.\n",
    "\n",
    "6. MultiGPU setup, when possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdDVnQvLkaAi"
   },
   "source": [
    "# ------------------------   Extras   -----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxY59vsPkb49"
   },
   "source": [
    "# Generating plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfXWZ4FNmzGx"
   },
   "source": [
    "### CHECKLIST:\n",
    "\n",
    "- is the `model_config` correct?\n",
    "- is the `deploy_config` correct?\n",
    "- is the `model_plugins` correct? This should not need to change for any of them.\n",
    "\n",
    "- is the `model_functions` correct? Cross-reference to `model_config`!\n",
    "\n",
    "- is the `dataloader_mode` correct?\n",
    "- is the `batch_size` correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnunIsv5hGVf"
   },
   "outputs": [],
   "source": [
    "GENERATING_PLUGINS = True\n",
    "model_config = \"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cmumiscov-2.yml\"\n",
    "deploy_config = \"./GLAMOR/profiles/NELA/nela-covid-deploy.yml\"\n",
    "model_plugins = \"./GLAMOR/profiles/NELA/plugins.yml\"\n",
    "model_functions = [\"./GLAMOR/profiles/MiDAS/midas-dataset.py\",\n",
    "                    \"./GLAMOR/profiles/MiDAS/midas-expert.py\"]\n",
    "\n",
    "dataloader_mode = \"train\" # CHANGE THIS IF DEBUGGING\n",
    "batch_size = 128          # CHANGE THIS IF TOO SLOW OR CRASHING\n",
    "# EXTRAS\n",
    "deployment_functions = \"./GLAMOR/profiles/NELA/deploy-plugin-usage.py\"  # use generation.py is generating plugins\n",
    "epochs = 1                # CHANGE THIS IF GENERATING PLUGINS ----> 6       ELSE, use 1 epoch\n",
    "ignore_plugins = []       # CHANGE THIS IF PLUGINS NEED RESETTING ----> [\"KMP-l2\", \"KMP-cos\", \"RL-midas\"]\n",
    "if GENERATING_PLUGINS:\n",
    "  ignore_plugins = [\"KMP-l2\", \"KMP-cos\", \"RL-midas\"]\n",
    "  epochs = 6\n",
    "  deployment_functions =  \"./GLAMOR/profiles/NELA/deploy-plugin-generation.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HeB0G6csm9CW"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3lKPAzOm8_v"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "from ednaml.core import EdnaDeploy\n",
    "from ednaml.plugins.KMeansProxy import KMeansProxy\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGWP-Lzl5K86"
   },
   "outputs": [],
   "source": [
    "ed = EdnaDeploy(config=model_config, deploy=[deploy_config, model_plugins] , dataloader_mode = dataloader_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH2jXma3xhc3"
   },
   "source": [
    "We make sure we have the correct `DATAREADER`. Here we use the one from `EXECUTION`, because it comes from the model we are loading, ensuring we are working with the model's training/testing data.\n",
    "\n",
    "We can also manually set `EPOCHS` here, for debugging or fast deployment editing purposes. Since deployments are ephemeral and not logged (for the time being), this is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sj2MR0k-XHOm"
   },
   "outputs": [],
   "source": [
    "ed.cfg.DEPLOYMENT.DATAREADER = ed.cfg.EXECUTION.DATAREADER\n",
    "#\n",
    "ed.cfg.DEPLOYMENT.DATAREADER.DATAREADER = \"AlbertReader\"\n",
    "ed.cfg.TEST_TRANSFORMATION.BATCH_SIZE = batch_size\n",
    "ed.cfg.DEPLOYMENT.EPOCHS = epochs\n",
    "ed.cfg.DEPLOYMENT.PLUGIN.HOOKS = 'warmup'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lG-X0lN3x5pa"
   },
   "source": [
    "If needed, go into the files and make sure the correct functions are registered with EdnaML, specifically the correct deployment plugin.\n",
    "\n",
    "There is one deployment plugin for writing to an output, and one for not writing to an output (for generating the plugins and doing nothing with the actual returns.\n",
    "\n",
    "**`NOTE: potential bug. midas-dataset also contains MiDASGenerator now, but this part NEEDS to use AlBERTReader. Solution. Deregister MiDASGenerator from midas-datasert. Solution: integrated MiDASGenerator and AlbertReader with datalabels.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1wIwei15S04"
   },
   "outputs": [],
   "source": [
    "ed.add(model_functions)\n",
    "ed.add(deployment_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HWfgOo9M3KGX"
   },
   "outputs": [],
   "source": [
    "ed.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQSP4Otj3UsV"
   },
   "outputs": [],
   "source": [
    "ed.deploy(ignore_plugins = ignore_plugins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gUSjVY8ao8C"
   },
   "outputs": [],
   "source": [
    "ed.model.plugins['RL-midas'].save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DArM05AeVeir"
   },
   "outputs": [],
   "source": [
    "ed.model.plugins['RL-midas'].save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51AtEjJFl97w"
   },
   "source": [
    "# Cross Validation Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xHDwXl-3OTA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsZv09uPwHKb"
   },
   "source": [
    "## Testing NELA/Fakeddit on MiDAS Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yer5K3o9_Njq"
   },
   "outputs": [],
   "source": [
    "# NELA\n",
    "cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
    "model_file = \"./GLAMOR/profiles/NELA/nela.py\"\n",
    "# Fakeddit\n",
    "#cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
    "#model_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZ1znkUPwJ5z"
   },
   "outputs": [],
   "source": [
    "data_folder = \"Data\"\n",
    "datasets_folders = glob.glob(os.path.join(data_folder, \"*\"))\n",
    "datasets_folders = [os.path.basename(item) for item in datasets_folders if os.path.basename(item) not in [\"coaid_tweets\", \"recov\", \"nela-elections-2020\", \"all_train.tsv\", \"all_test_public.tsv\", \"nela-covid-2020\", \"nela-gt-2020\", \"all_validate.tsv\"]]\n",
    "datasets_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFbzthaa2KI4"
   },
   "outputs": [],
   "source": [
    "# set up the model\n",
    "eml = EdnaML(config=cfg, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
    "eml2 = EdnaML(config=\"./GLAMOR/profiles/MiDAS/encoder-experiments/midas-tsne.yml\",\n",
    "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
    "\n",
    "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
    "eml.cfg.EXECUTION.DATAREADER.DATAREADER = \"AlbertReader\"\n",
    "eml.cfg.EXECUTION.DATAREADER.CRAWLER_ARGS[\"include\"] = datasets_folders\n",
    "# So we have model loaded with correct parameters\n",
    "\n",
    "eml.add(model_file) #add model\n",
    "eml.add(\"./GLAMOR/profiles/MiDAS/midas-dataset.py\") # replace crawler\n",
    "eml.add(\"./GLAMOR/profiles/MiDAS/midas-trainer.py\") # replace trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vRzS3rI2KGY"
   },
   "outputs": [],
   "source": [
    "eml.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZNDv_rL-TnG"
   },
   "outputs": [],
   "source": [
    "preds, labels, classes, logits = eml.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my3xebM87AcV"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "print (\"Domain accuracies for %s\"%str(eml.cfg.SAVE.MODEL_QUALIFIER))\n",
    "for idx, dlabel in enumerate(range(max(labels[1]).item()+1)):\n",
    "  acc = torch.mean((preds[labels[1]==dlabel] == labels[0][labels[1]==dlabel]).float())\n",
    "  micro_fscore = np.mean(f1_score(labels[0][labels[1]==dlabel], preds[labels[1]==dlabel], average=\"micro\"))\n",
    "  weighted_fscore = np.mean(f1_score(labels[0][labels[1]==dlabel], preds[labels[1]==dlabel], average=\"weighted\"))\n",
    "  print (\"\\t Domain {0}\\t {1:0.3f} \\t{2:0.3f} \\t{3:0.3f}\\t\\t{4}\".format(datasets_folders[idx], acc, micro_fscore, weighted_fscore, torch.sum(labels[1]==dlabel).item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f--DYZ6S_dls"
   },
   "source": [
    "## Testing MIDAS Models on NELA/Fakeddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZbcIvgDWf31"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFozzqfkAjb6"
   },
   "outputs": [],
   "source": [
    "expert_config = \"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covrumor-1.yml\"\n",
    "\"\"\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-kagglefnlong-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covrumor-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covidfn-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-covid_cq-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cov19fntitle-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cov19fntext-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-coaid_news-1.yml\"\n",
    "\"./GLAMOR/profiles/MiDAS/expert-experiments/midas-cmumiscov-2.yml\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHFm8FJa_tB-"
   },
   "outputs": [],
   "source": [
    "# NELA\n",
    "#cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
    "#crawler_file = \"./GLAMOR/profiles/NELA/nela.py\"\n",
    "# Fakeddit\n",
    "cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
    "crawler_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_msnPJpywL4z"
   },
   "outputs": [],
   "source": [
    "# set up the model\n",
    "eml = EdnaML(config=expert_config, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
    "eml2 = EdnaML(config=cfg,\n",
    "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
    "\n",
    "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
    "# So we have model loaded with correct parameters\n",
    "\n",
    "eml.add(crawler_file) # add crawler/trainer\n",
    "eml.add(\"./GLAMOR/profiles/MiDAS/midas-expert.py\") #replace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPa5Rg9yACYX"
   },
   "outputs": [],
   "source": [
    "eml.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTbhbcjUADOP"
   },
   "outputs": [],
   "source": [
    "preds, labels, classes, logits = eml.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1tM_2VaBCWva"
   },
   "outputs": [],
   "source": [
    "labels[labels!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_CSFxjPCWva"
   },
   "outputs": [],
   "source": [
    "accuracy = (preds != labels).sum().float() / float(labels.size(0))\n",
    "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMjNkF9q9Ihz"
   },
   "source": [
    "## NELA <-> Fakeddit cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08DGKH029K4S"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ednaml\n",
    "import glob, os\n",
    "from ednaml.core import EdnaDeploy, EdnaML\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECXQSK4W9N6X"
   },
   "outputs": [],
   "source": [
    "# NELA\n",
    "b_cfg = \"./GLAMOR/profiles/NELA/nela-covid-v1.yml\"\n",
    "b_crawlerfile = \"./GLAMOR/profiles/NELA/nela.py\"\n",
    "# Fakeddit\n",
    "cfg = \"./GLAMOR/profiles/Fakeddit/fakeddit-v3.yml\"\n",
    "model_file = \"./GLAMOR/profiles/Fakeddit/fakeddit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xcQT02459UZW"
   },
   "outputs": [],
   "source": [
    "# set up the model\n",
    "eml = EdnaML(config=cfg, mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")\n",
    "eml2 = EdnaML(config=b_cfg,\n",
    "                mode=\"test\", test_only = True, logger_save_name=\"cd-eval\")  # weights path should be automatically inferred!!! :)\n",
    "\n",
    "eml.cfg.EXECUTION.DATAREADER = eml2.cfg.EXECUTION.DATAREADER\n",
    "# So we have model loaded with correct parameters\n",
    "\n",
    "eml.add(b_crawlerfile) #add crawler/trainer\n",
    "eml.add(model_file) # replace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHxhTQcW-E86"
   },
   "outputs": [],
   "source": [
    "eml.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dkk2B45j-EtK"
   },
   "outputs": [],
   "source": [
    "preds, labels, classes, logits = eml.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2YFkjvcgDFx"
   },
   "source": [
    "#### Converting the fakeddit true labels to other 1/0 versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGsJx4o-BsRM"
   },
   "outputs": [],
   "source": [
    "labels[labels!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nM35mp48CEW-"
   },
   "outputs": [],
   "source": [
    "accuracy = (preds == labels).sum().float() / float(labels.size(0))\n",
    "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_zzDtRf-oRj"
   },
   "outputs": [],
   "source": [
    "!rm -rf -- test-datashard-artifacts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4t8TuXCxgGLe"
   },
   "source": [
    "#### Converting the Fakeddit predictions to other versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKmXAGnP-qo3"
   },
   "outputs": [],
   "source": [
    "preds[preds!=0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qTv3_9DH_il5"
   },
   "outputs": [],
   "source": [
    "accuracy = (preds == labels).sum().float() / float(labels.size(0))\n",
    "print(\"\\tAccuracy: {:.3%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_MGRfew7gMw0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "d5j3WfN0fpIT",
    "0KjvT_ZJovGY",
    "uqCdOF7tCj8N",
    "FOwc42Dv5i6H",
    "bBLksdNI5Ukb",
    "kqSK-TBM5Z9v",
    "vUiGLd_6sbPG",
    "FBwOfPCRsuvq",
    "lBH_VHmGAqbX",
    "EU53fUFKuFEb",
    "WETqeAOTuoGl",
    "5rmrRbkmCzBW",
    "kMcmognzvBq2",
    "UdDVnQvLkaAi",
    "uxY59vsPkb49",
    "PfXWZ4FNmzGx",
    "51AtEjJFl97w",
    "f--DYZ6S_dls"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0126ac625ee3483abd82020e6fb7e5e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e84e6f2b9604d85b8b9e9e20ed27342",
       "IPY_MODEL_506726ca155a4c53aaebb3beaa799f2b",
       "IPY_MODEL_c6b19b4a4e64496c837bda7cc2bddd9e"
      ],
      "layout": "IPY_MODEL_e5a7aa355be9465bb255259c0b20a290"
     }
    },
    "0832bd86bbe34fb6be862ee277bc35d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5123670e39dc40b3a32a2ee8bac58c05",
      "placeholder": "​",
      "style": "IPY_MODEL_6dbb5a55fd364835b8f6c9a9ef5a99d4",
      "value": " 47.4M/47.4M [00:00&lt;00:00, 202MB/s]"
     }
    },
    "1437dcb8e72e47bcaee86f449d9ea988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26d21e135f0a45f4a3b3815640820127",
       "IPY_MODEL_68c32fa3f36a468594630561113fc413",
       "IPY_MODEL_48c8eda152c24ec8a30e76d04fcba80a"
      ],
      "layout": "IPY_MODEL_76658d325ca94c609bd7b0b12f5e712a"
     }
    },
    "208e6906fc8441939c6bf772e535ae51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee3ab4c1db1443abc2f0fbf5e6f3eea",
      "max": 760289,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f7356c6607b4d179842af7f76c5f718",
      "value": 760289
     }
    },
    "213669cd5e044ceba85f9fdc6288f508": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2181cb6323864c70835626fbebbadb78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22879b070c9c44c4a21c81adf2e21b16": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "234c95fe23914f2892520cf915f93b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2181cb6323864c70835626fbebbadb78",
      "placeholder": "​",
      "style": "IPY_MODEL_e091a3cc32af43cfb91ff0045ef1e135",
      "value": "Downloading (…)ve/main/spiece.model: 100%"
     }
    },
    "26d21e135f0a45f4a3b3815640820127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_29e67a65e4644c65a1139315d3e8aa88",
      "placeholder": "​",
      "style": "IPY_MODEL_d02d5ed1cfa54810a65f2760931d658d",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "29e67a65e4644c65a1139315d3e8aa88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aef35ff068549c7aad0d8cc2dffd5cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ba9f72aa1384cf3ab53337075f37595": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39fe5260da0d4eed961ef568439129a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "43031f69a5f24a6e887b0a88453607fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44c40375cf144643acfed61faba76c85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48c8eda152c24ec8a30e76d04fcba80a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b346f92c5474fb89628e8945d6f50db",
      "placeholder": "​",
      "style": "IPY_MODEL_44c40375cf144643acfed61faba76c85",
      "value": " 684/684 [00:00&lt;00:00, 50.5kB/s]"
     }
    },
    "4ee3ab4c1db1443abc2f0fbf5e6f3eea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "506726ca155a4c53aaebb3beaa799f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22879b070c9c44c4a21c81adf2e21b16",
      "max": 1312669,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_617df262a1974dcfaec3bf2087f983b8",
      "value": 1312669
     }
    },
    "5123670e39dc40b3a32a2ee8bac58c05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56cc7969932a41fda43c0ebadf3d461d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b346f92c5474fb89628e8945d6f50db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5eeb8f4c346a4faaa7bcb38e6aea46d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_234c95fe23914f2892520cf915f93b69",
       "IPY_MODEL_208e6906fc8441939c6bf772e535ae51",
       "IPY_MODEL_fe60701859c4438295b78c3cfa5a2959"
      ],
      "layout": "IPY_MODEL_e5ce333f6962496b82e1ec28f8273bb3"
     }
    },
    "5f7356c6607b4d179842af7f76c5f718": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "617df262a1974dcfaec3bf2087f983b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68c32fa3f36a468594630561113fc413": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43031f69a5f24a6e887b0a88453607fd",
      "max": 684,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec0f092cce1d4aa0bece4ed6ae5ce6a6",
      "value": 684
     }
    },
    "6dbb5a55fd364835b8f6c9a9ef5a99d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71f734ed764e4f8080851fcbb44d21ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0afdcb7490e4078b1121147b4253375",
       "IPY_MODEL_f732452fc9914305b101d8952fcdeb54",
       "IPY_MODEL_0832bd86bbe34fb6be862ee277bc35d9"
      ],
      "layout": "IPY_MODEL_2ba9f72aa1384cf3ab53337075f37595"
     }
    },
    "76658d325ca94c609bd7b0b12f5e712a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791216707e14473ea42aaa34f794c255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "919131d306424b18b71fd4cc0f32c4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e84e6f2b9604d85b8b9e9e20ed27342": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f983a4dc6b734f6bab93d45465a4d532",
      "placeholder": "​",
      "style": "IPY_MODEL_56cc7969932a41fda43c0ebadf3d461d",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "a3911953fe9a48edb216286426690a92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b563ebb5f5834c0ab534e33c0855d74f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c0afdcb7490e4078b1121147b4253375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_791216707e14473ea42aaa34f794c255",
      "placeholder": "​",
      "style": "IPY_MODEL_b563ebb5f5834c0ab534e33c0855d74f",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "c6b19b4a4e64496c837bda7cc2bddd9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd3acc7636594daaa8958b3ed70f06e2",
      "placeholder": "​",
      "style": "IPY_MODEL_213669cd5e044ceba85f9fdc6288f508",
      "value": " 1.31M/1.31M [00:00&lt;00:00, 33.8MB/s]"
     }
    },
    "cd3acc7636594daaa8958b3ed70f06e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d02d5ed1cfa54810a65f2760931d658d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e091a3cc32af43cfb91ff0045ef1e135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5a7aa355be9465bb255259c0b20a290": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5ce333f6962496b82e1ec28f8273bb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec0f092cce1d4aa0bece4ed6ae5ce6a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f732452fc9914305b101d8952fcdeb54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_919131d306424b18b71fd4cc0f32c4f7",
      "max": 47372894,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39fe5260da0d4eed961ef568439129a3",
      "value": 47372894
     }
    },
    "f983a4dc6b734f6bab93d45465a4d532": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe60701859c4438295b78c3cfa5a2959": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2aef35ff068549c7aad0d8cc2dffd5cc",
      "placeholder": "​",
      "style": "IPY_MODEL_a3911953fe9a48edb216286426690a92",
      "value": " 760k/760k [00:00&lt;00:00, 3.69MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
